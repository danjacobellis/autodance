{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3510095-2530-47e4-9be4-f7195bdc9d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import PIL.Image\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datasets\n",
    "import math\n",
    "import random\n",
    "import av\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "from IPython.display import HTML\n",
    "from types import SimpleNamespace\n",
    "from timm.optim import Mars\n",
    "from fastprogress import progress_bar, master_bar\n",
    "from torchvision.transforms.v2 import ToPILImage, PILToTensor, CenterCrop, RandomCrop\n",
    "from autocodec.codec import AutoCodecND, pil_to_latent, latent_to_pil\n",
    "from IPython.display import display, clear_output\n",
    "from ipywidgets import interact\n",
    "from piq import ssim, psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b9dab96-10b8-4c95-b58c-14a305f1c7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ff1ddd9bdf4681bec62330b744a0d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3ee18db5234e598da896d9e707cc71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0be5e774d104623b5c077f2b804f0c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5699f2d18fc4f3e8522c18739d7bb9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device=\"cuda\"\n",
    "dataset = datasets.load_dataset(\"danjacobellis/nuscenes_front\",split='validation').cast_column('video', datasets.Video()).with_format(\"torch\")\n",
    "subset = dataset.select(range(40)).filter(lambda s: len(s['video'])>=256)\n",
    "checkpoint = torch.load(\"../hf/dance/LF_nuscenes_f8c24_v1.2.pth\",weights_only=False)\n",
    "config = checkpoint['config']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ec92957-1ef0-4d6d-8183-ca4c667e6819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275.498072 M parameters\n"
     ]
    }
   ],
   "source": [
    "model = AutoCodecND(\n",
    "    dim=3,\n",
    "    input_channels=config.input_channels,\n",
    "    J = int(np.log2(config.F)),\n",
    "    latent_dim=config.latent_dim,\n",
    "    lightweight_encode = config.lightweight_encode,\n",
    "    lightweight_decode = config.lightweight_decode,\n",
    "    post_filter = config.post_filter\n",
    ").to(device)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()\n",
    "print(f\"{sum(p.numel() for p in model.parameters())/1e6} M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a5b9723-ee73-4804-a748-c38a155ec78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video = subset[0]['video']\n",
    "# ℓ = 256\n",
    "# x = video.get_batch(range(ℓ)).permute(3, 0, 1, 2)\n",
    "# h = 256; w = 256\n",
    "# x = CenterCrop((h,w))(x).unsqueeze(0).to(device)\n",
    "# x = x.to(torch.float)/127.5 - 1.0\n",
    "\n",
    "# orig_dim = x.numel()\n",
    "# with torch.no_grad():\n",
    "#     z = model.encode(x)\n",
    "#     latent = model.quantize.compand(z).round()\n",
    "# latent = einops.rearrange(latent, 'b c d h w -> b (c d) h w').cpu()\n",
    "\n",
    "# webp = latent_to_pil(latent, n_bits=8, C=3)\n",
    "# display(webp[0])\n",
    "# buff = io.BytesIO()\n",
    "# webp[0].save(buff, format='WEBP', lossless=True)\n",
    "# size_bytes = len(buff.getbuffer())\n",
    "\n",
    "# print(f\"Compressed size: {size_bytes / 1e3:.2f} KB\")\n",
    "# print(f\"Compression ratio: {orig_dim / size_bytes:.2f}x\")\n",
    "# print(f\"Dimension reduction: {orig_dim / latent.numel():.2f}x\")\n",
    "\n",
    "# latent_decoded = pil_to_latent(webp, N=latent.shape[1], n_bits=8, C=3)\n",
    "# latent_decoded = einops.rearrange(latent_decoded, 'b (c d) h w -> b c d h w', d=32).to(device)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     x_hat = model.decode(latent_decoded).clamp(-1, 1)\n",
    "\n",
    "# mse = torch.nn.functional.mse_loss(x, x_hat)\n",
    "# PSNR = -10 * mse.log10().item() + 6.02\n",
    "\n",
    "# print(f\"PSNR: {PSNR:.2f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8af945af-9a26-4916-a002-1ddc944fdd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_video_codec(sample):\n",
    "\n",
    "    video = sample['video']\n",
    "    num_frames = 256\n",
    "    x_orig = video.get_batch(range(num_frames)).permute(3, 0, 1, 2)\n",
    "    h = 256; w = 256;\n",
    "    x_orig_cropped = CenterCrop((h,w))(x_orig).unsqueeze(0).to(device)\n",
    "    x = x_orig_cropped.to(torch.float)/127.5 - 1.0\n",
    "    \n",
    "    orig_dim = x.numel()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x)\n",
    "        latent = model.quantize.compand(z).round()\n",
    "    latent = einops.rearrange(latent, 'b c d h w -> b (c d) h w').cpu()\n",
    "    \n",
    "    webp = latent_to_pil(latent, n_bits=8, C=3)\n",
    "    buff = io.BytesIO()\n",
    "    webp[0].save(buff, format='WEBP', lossless=True)\n",
    "    size_bytes = len(buff.getbuffer())\n",
    "    latent_decoded = pil_to_latent(webp, N=latent.shape[1], n_bits=8, C=3)\n",
    "    latent_decoded = einops.rearrange(latent_decoded, 'b (c d) h w -> b c d h w', d=32).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        x_hat = model.decode(latent_decoded).clamp(-1, 1)\n",
    "    \n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    \n",
    "    for frame_idx in range(x.shape[1]):\n",
    "        x_frame_orig = x[:, :, frame_idx]\n",
    "        x_frame_hat = x_hat[:, :, frame_idx]\n",
    "    \n",
    "        mse = torch.nn.functional.mse_loss(x_frame_orig, x_frame_hat)\n",
    "        psnr_val = -10 * mse.log10().item() + 6.02 # PSNR in dB for [-1, 1] range. However, original code uses 20*log10(2). Let's use that.\n",
    "        psnr_val = -10 * mse.log10().item() + 20*np.log10(2)\n",
    "        psnr_values.append(psnr_val)\n",
    "    \n",
    "        x_frame_orig_01 = x_frame_orig / 2 + 0.5\n",
    "        x_frame_hat_01 = x_frame_hat / 2 + 0.5\n",
    "        ssim_val = ssim(x_frame_orig_01, x_frame_hat_01, data_range=1.0).item() # piq ssim returns scalar\n",
    "        ssim_values.append(ssim_val)\n",
    "    \n",
    "    avg_psnr = np.mean(psnr_values)\n",
    "    avg_ssim = np.mean(ssim_values)\n",
    "    video_cr = orig_dim / size_bytes\n",
    "\n",
    "    return {\n",
    "        'video_PSNR': avg_psnr,\n",
    "        'video_SSIM': avg_ssim,\n",
    "        'video_CR': video_cr\n",
    "    }\n",
    "\n",
    "metrics = [\n",
    "    'video_PSNR',\n",
    "    'video_SSIM',\n",
    "    'video_CR'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe066abe-edeb-421f-bf94-6565491df57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "---\n",
      "video_PSNR: 33.52024459838867\n",
      "video_SSIM: 0.8803455829620361\n",
      "video_CR: 128.71095275878906\n",
      "median\n",
      "---\n",
      "video_PSNR: 33.52024459838867\n",
      "video_SSIM: 0.8803455233573914\n",
      "video_CR: 128.71095275878906\n"
     ]
    }
   ],
   "source": [
    "results_dataset = subset.select(range(2)).map(eval_video_codec)\n",
    "print(\"mean\\n---\")\n",
    "for metric in metrics:\n",
    "    μ = results_dataset[metric].mean()\n",
    "    print(f\"{metric}: {μ}\")\n",
    "\n",
    "print(\"median\\n---\")\n",
    "for metric in metrics:\n",
    "    μ = results_dataset[metric].median()\n",
    "    print(f\"{metric}: {μ}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
