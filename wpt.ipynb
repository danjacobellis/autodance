{
 "cells": [
  {
   "cell_type": "raw",
   "id": "996e9ab4-8b43-4e20-8f3a-1877dcb62848",
   "metadata": {},
   "source": [
    "I'm attempting to extend the 1d and 2d transforms to 3d.\n",
    "\n",
    "wpt.ipynb\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a6ad368-7205-4a92-9f5c-7f7e7304ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pywt\n",
    "import einops\n",
    "from torch.autograd import Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2cd2c25-f1b0-48d7-b612-16c8facda1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll(x, n, dim, make_even=False):\n",
    "    if n < 0:\n",
    "        n = x.shape[dim] + n\n",
    "\n",
    "    if make_even and x.shape[dim] % 2 == 1:\n",
    "        end = 1\n",
    "    else:\n",
    "        end = 0\n",
    "\n",
    "    if dim == 0:\n",
    "        return torch.cat((x[-n:], x[:-n+end]), dim=0)\n",
    "    elif dim == 1:\n",
    "        return torch.cat((x[:,-n:], x[:,:-n+end]), dim=1)\n",
    "    elif dim == 2 or dim == -2:\n",
    "        return torch.cat((x[:,:,-n:], x[:,:,:-n+end]), dim=2)\n",
    "    elif dim == 3 or dim == -1:\n",
    "        return torch.cat((x[:,:,:,-n:], x[:,:,:,:-n+end]), dim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bcea4a5-e98a-433f-a641-b77ad23af179",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prep_filt_afb1d(h0, h1, device=None):\n",
    "    h0 = np.array(h0[::-1]).ravel()\n",
    "    h1 = np.array(h1[::-1]).ravel()\n",
    "    t = torch.get_default_dtype()\n",
    "    h0 = torch.tensor(h0, device=device, dtype=t).reshape((1, 1, -1))\n",
    "    h1 = torch.tensor(h1, device=device, dtype=t).reshape((1, 1, -1))\n",
    "    return h0, h1\n",
    "\n",
    "def afb1d(x, h0, h1, dim=-1):\n",
    "    C = x.shape[1]\n",
    "    # Convert the dim to positive\n",
    "    d = dim % 4\n",
    "    s = (2, 1) if d == 2 else (1, 2)\n",
    "    N = x.shape[d]\n",
    "    # If h0, h1 are not tensors, make them. If they are, then assume that they\n",
    "    # are in the right order\n",
    "    if not isinstance(h0, torch.Tensor):\n",
    "        h0 = torch.tensor(np.copy(np.array(h0).ravel()[::-1]),\n",
    "                          dtype=torch.float, device=x.device)\n",
    "    if not isinstance(h1, torch.Tensor):\n",
    "        h1 = torch.tensor(np.copy(np.array(h1).ravel()[::-1]),\n",
    "                          dtype=torch.float, device=x.device)\n",
    "    L = h0.numel()\n",
    "    L2 = L // 2\n",
    "    shape = [1,1,1,1]\n",
    "    shape[d] = L\n",
    "    # If h aren't in the right shape, make them so\n",
    "    if h0.shape != tuple(shape):\n",
    "        h0 = h0.reshape(*shape)\n",
    "    if h1.shape != tuple(shape):\n",
    "        h1 = h1.reshape(*shape)\n",
    "    h = torch.cat([h0, h1] * C, dim=0)\n",
    "\n",
    "    if x.shape[dim] % 2 == 1:\n",
    "        if d == 2:\n",
    "            x = torch.cat((x, x[:,:,-1:]), dim=2)\n",
    "        else:\n",
    "            x = torch.cat((x, x[:,:,:,-1:]), dim=3)\n",
    "        N += 1\n",
    "    x = roll(x, -L2, dim=d)\n",
    "    pad = (L-1, 0) if d == 2 else (0, L-1)\n",
    "    lohi = F.conv2d(x, h, padding=pad, stride=s, groups=C)\n",
    "    N2 = N//2\n",
    "    if d == 2:\n",
    "        lohi[:,:,:L2] = lohi[:,:,:L2] + lohi[:,:,N2:N2+L2]\n",
    "        lohi = lohi[:,:,:N2]\n",
    "    else:\n",
    "        lohi[:,:,:,:L2] = lohi[:,:,:,:L2] + lohi[:,:,:,N2:N2+L2]\n",
    "        lohi = lohi[:,:,:,:N2]\n",
    "\n",
    "    return lohi\n",
    "        \n",
    "class AFB1D(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, h0, h1):\n",
    "\n",
    "        # Make inputs 4d\n",
    "        x = x[:, :, None, :]\n",
    "        h0 = h0[:, :, None, :]\n",
    "        h1 = h1[:, :, None, :]\n",
    "\n",
    "        # Save for backwards\n",
    "        ctx.save_for_backward(h0, h1)\n",
    "        ctx.shape = x.shape[3]\n",
    "\n",
    "        lohi = afb1d(x, h0, h1, dim=3)\n",
    "        x0 = lohi[:, ::2, 0].contiguous()\n",
    "        x1 = lohi[:, 1::2, 0].contiguous()\n",
    "        return x0, x1\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, dx0, dx1):\n",
    "        dx = None\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            h0, h1 = ctx.saved_tensors\n",
    "\n",
    "            # Make grads 4d\n",
    "            dx0 = dx0[:, :, None, :]\n",
    "            dx1 = dx1[:, :, None, :]\n",
    "\n",
    "            dx = sfb1d(dx0, dx1, h0, h1, dim=3)[:, :, 0]\n",
    "\n",
    "            # Check for odd input\n",
    "            if dx.shape[2] > ctx.shape:\n",
    "                dx = dx[:, :, :ctx.shape]\n",
    "\n",
    "        return dx, None, None, None, None, None\n",
    "\n",
    "def prep_filt_sfb1d(g0, g1, device=None):\n",
    "    g0 = np.array(g0).ravel()\n",
    "    g1 = np.array(g1).ravel()\n",
    "    t = torch.get_default_dtype()\n",
    "    g0 = torch.tensor(g0, device=device, dtype=t).reshape((1, 1, -1))\n",
    "    g1 = torch.tensor(g1, device=device, dtype=t).reshape((1, 1, -1))\n",
    "\n",
    "    return g0, g1\n",
    "\n",
    "def sfb1d(lo, hi, g0, g1, dim=-1):\n",
    "    C = lo.shape[1]\n",
    "    d = dim % 4\n",
    "    if not isinstance(g0, torch.Tensor):\n",
    "        g0 = torch.tensor(np.copy(np.array(g0).ravel()),\n",
    "                          dtype=torch.float, device=lo.device)\n",
    "    if not isinstance(g1, torch.Tensor):\n",
    "        g1 = torch.tensor(np.copy(np.array(g1).ravel()),\n",
    "                          dtype=torch.float, device=lo.device)\n",
    "    L = g0.numel()\n",
    "    shape = [1,1,1,1]\n",
    "    shape[d] = L\n",
    "    N = 2*lo.shape[d]\n",
    "    # If g aren't in the right shape, make them so\n",
    "    if g0.shape != tuple(shape):\n",
    "        g0 = g0.reshape(*shape)\n",
    "    if g1.shape != tuple(shape):\n",
    "        g1 = g1.reshape(*shape)\n",
    "\n",
    "    s = (2, 1) if d == 2 else (1,2)\n",
    "    g0 = torch.cat([g0]*C,dim=0)\n",
    "    g1 = torch.cat([g1]*C,dim=0)\n",
    "    y = F.conv_transpose2d(lo, g0, stride=s, groups=C) + \\\n",
    "        F.conv_transpose2d(hi, g1, stride=s, groups=C)\n",
    "    if d == 2:\n",
    "        y[:,:,:L-2] = y[:,:,:L-2] + y[:,:,N:N+L-2]\n",
    "        y = y[:,:,:N]\n",
    "    else:\n",
    "        y[:,:,:,:L-2] = y[:,:,:,:L-2] + y[:,:,:,N:N+L-2]\n",
    "        y = y[:,:,:,:N]\n",
    "    y = roll(y, 1-L//2, dim=dim)\n",
    "\n",
    "    return y\n",
    "\n",
    "class SFB1D(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, low, high, g0, g1):\n",
    "        # Make into a 2d tensor with 1 row\n",
    "        low = low[:, :, None, :]\n",
    "        high = high[:, :, None, :]\n",
    "        g0 = g0[:, :, None, :]\n",
    "        g1 = g1[:, :, None, :]\n",
    "\n",
    "        ctx.save_for_backward(g0, g1)\n",
    "\n",
    "        return sfb1d(low, high, g0, g1, dim=3)[:, :, 0]\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, dy):\n",
    "        dlow, dhigh = None, None\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            g0, g1, = ctx.saved_tensors\n",
    "            dy = dy[:, :, None, :]\n",
    "\n",
    "            dx = afb1d(dy, g0, g1, dim=3)\n",
    "\n",
    "            dlow = dx[:, ::2, 0].contiguous()\n",
    "            dhigh = dx[:, 1::2, 0].contiguous()\n",
    "        return dlow, dhigh, None, None, None, None, None\n",
    "\n",
    "class DWT1DForward(nn.Module):\n",
    "    def __init__(self, J=1, wave='db1'):\n",
    "        super().__init__()\n",
    "        if isinstance(wave, str):\n",
    "            wave = pywt.Wavelet(wave)\n",
    "        if isinstance(wave, pywt.Wavelet):\n",
    "            h0, h1 = wave.dec_lo, wave.dec_hi\n",
    "        else:\n",
    "            assert len(wave) == 2\n",
    "            h0, h1 = wave[0], wave[1]\n",
    "        filts = prep_filt_afb1d(h0, h1)\n",
    "        self.register_buffer('h0', filts[0])\n",
    "        self.register_buffer('h1', filts[1])\n",
    "        self.J = J\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert x.ndim == 3, \"Can only handle 3d inputs (N, C, L)\"\n",
    "        highs = []\n",
    "        x0 = x\n",
    "        for j in range(self.J):\n",
    "            x0, x1 = AFB1D.apply(x0, self.h0, self.h1)\n",
    "            highs.append(x1)\n",
    "        return x0, highs\n",
    "        \n",
    "class WPT1D(torch.nn.Module):\n",
    "    def __init__(self, wt=DWT1DForward(wave='bior4.4'), J=4):\n",
    "        super().__init__()\n",
    "        self.wt = wt\n",
    "        self.J = J\n",
    "\n",
    "    def analysis_one_level(self,x):\n",
    "        L, H = self.wt(x)\n",
    "        X = torch.cat([L.unsqueeze(2),H[0].unsqueeze(2)],dim=2)\n",
    "        X = einops.rearrange(X, 'b c f ℓ -> b (c f) ℓ')\n",
    "        return X\n",
    "\n",
    "    def wavelet_analysis(self, x, J):\n",
    "        for _ in range(J):\n",
    "            x = self.analysis_one_level(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.wavelet_analysis(x, J=self.J)\n",
    "        \n",
    "class DWT1DInverse(nn.Module):\n",
    "    def __init__(self, wave='db1'):\n",
    "        super().__init__()\n",
    "        if isinstance(wave, str):\n",
    "            wave = pywt.Wavelet(wave)\n",
    "        if isinstance(wave, pywt.Wavelet):\n",
    "            g0, g1 = wave.rec_lo, wave.rec_hi\n",
    "        else:\n",
    "            assert len(wave) == 2\n",
    "            g0, g1 = wave[0], wave[1]\n",
    "        filts = prep_filt_sfb1d(g0, g1)\n",
    "        self.register_buffer('g0', filts[0])\n",
    "        self.register_buffer('g1', filts[1])\n",
    "\n",
    "    def forward(self, coeffs):\n",
    "        x0, highs = coeffs\n",
    "        assert x0.ndim == 3, \"Can only handle 3d inputs (N, C, L)\"\n",
    "        for x1 in highs[::-1]:\n",
    "            if x1 is None:\n",
    "                x1 = torch.zeros_like(x0)\n",
    "            if x0.shape[-1] > x1.shape[-1]:\n",
    "                x0 = x0[..., :-1]\n",
    "            x0 = SFB1D.apply(x0, x1, self.g0, self.g1)\n",
    "        return x0\n",
    "\n",
    "class IWPT1D(torch.nn.Module):\n",
    "    def __init__(self, iwt=DWT1DInverse(wave='bior4.4'), J=4):\n",
    "        super().__init__()\n",
    "        self.iwt = iwt\n",
    "        self.J = J\n",
    "\n",
    "    def synthesis_one_level(self, X):\n",
    "        X = einops.rearrange(X, 'b (c f) ℓ -> b c f ℓ', f=2)\n",
    "        L, H = torch.split(X, [1, 1], dim=2)\n",
    "        L = L.squeeze(2)\n",
    "        H = [H.squeeze(2)]\n",
    "        y = self.iwt((L, H))\n",
    "        return y\n",
    "\n",
    "    def wavelet_synthesis(self, x, J):\n",
    "        for _ in range(J):\n",
    "            x = self.synthesis_one_level(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.wavelet_synthesis(x, J=self.J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6465dd31-d2ae-4b5f-872a-501e11457047",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1d = torch.randn(2, 3, 4096)\n",
    "wt1d = DWT1DForward(wave='bior4.4')\n",
    "wpt1d = WPT1D(wt=wt1d, J=3)\n",
    "iwt1d = DWT1DInverse(wave='bior4.4')\n",
    "iwpt1d = IWPT1D(iwt=iwt1d, J=3)\n",
    "with torch.no_grad():\n",
    "    X1d = wpt1d(x1d)\n",
    "    xhat1d = iwpt1d(X1d)\n",
    "assert (xhat1d - x1d).abs().max() < 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a93fb734-9e91-4f20-82cd-265985ebc87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_filt_afb2d(h0_col, h1_col, h0_row=None, h1_row=None, device=None):\n",
    "    h0_col, h1_col = prep_filt_afb1d(h0_col, h1_col, device)\n",
    "    if h0_row is None:\n",
    "        h0_row, h1_row = h0_col, h1_col\n",
    "    else:\n",
    "        h0_row, h1_row = prep_filt_afb1d(h0_row, h1_row, device)\n",
    "\n",
    "    h0_col = h0_col.reshape((1, 1, -1, 1))\n",
    "    h1_col = h1_col.reshape((1, 1, -1, 1))\n",
    "    h0_row = h0_row.reshape((1, 1, 1, -1))\n",
    "    h1_row = h1_row.reshape((1, 1, 1, -1))\n",
    "    return h0_col, h1_col, h0_row, h1_row\n",
    "\n",
    "def afb2d(x, filts):\n",
    "    tensorize = [not isinstance(f, torch.Tensor) for f in filts]\n",
    "    if len(filts) == 2:\n",
    "        h0, h1 = filts\n",
    "        if True in tensorize:\n",
    "            h0_col, h1_col, h0_row, h1_row = prep_filt_afb2d(\n",
    "                h0, h1, device=x.device)\n",
    "        else:\n",
    "            h0_col = h0\n",
    "            h0_row = h0.transpose(2,3)\n",
    "            h1_col = h1\n",
    "            h1_row = h1.transpose(2,3)\n",
    "    elif len(filts) == 4:\n",
    "        if True in tensorize:\n",
    "            h0_col, h1_col, h0_row, h1_row = prep_filt_afb2d(\n",
    "                *filts, device=x.device)\n",
    "        else:\n",
    "            h0_col, h1_col, h0_row, h1_row = filts\n",
    "    else:\n",
    "        raise ValueError(\"Unknown form for input filts\")\n",
    "\n",
    "    lohi = afb1d(x, h0_row, h1_row, dim=3)\n",
    "    y = afb1d(lohi, h0_col, h1_col, dim=2)\n",
    "\n",
    "    return y\n",
    "\n",
    "class AFB2D(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, h0_row, h1_row, h0_col, h1_col):\n",
    "        ctx.save_for_backward(h0_row, h1_row, h0_col, h1_col)\n",
    "        ctx.shape = x.shape[-2:]\n",
    "        lohi = afb1d(x, h0_row, h1_row, dim=3)\n",
    "        y = afb1d(lohi, h0_col, h1_col, dim=2)\n",
    "        s = y.shape\n",
    "        y = y.reshape(s[0], -1, 4, s[-2], s[-1])\n",
    "        low = y[:,:,0].contiguous()\n",
    "        highs = y[:,:,1:].contiguous()\n",
    "        return low, highs\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, low, highs):\n",
    "        dx = None\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            h0_row, h1_row, h0_col, h1_col = ctx.saved_tensors\n",
    "            lh, hl, hh = torch.unbind(highs, dim=2)\n",
    "            lo = sfb1d(low, lh, h0_col, h1_col, dim=2)\n",
    "            hi = sfb1d(hl, hh, h0_col, h1_col, dim=2)\n",
    "            dx = sfb1d(lo, hi, h0_row, h1_row, dim=3)\n",
    "            if dx.shape[-2] > ctx.shape[-2] and dx.shape[-1] > ctx.shape[-1]:\n",
    "                dx = dx[:,:,:ctx.shape[-2], :ctx.shape[-1]]\n",
    "            elif dx.shape[-2] > ctx.shape[-2]:\n",
    "                dx = dx[:,:,:ctx.shape[-2]]\n",
    "            elif dx.shape[-1] > ctx.shape[-1]:\n",
    "                dx = dx[:,:,:,:ctx.shape[-1]]\n",
    "        return dx, None, None, None, None, None\n",
    "\n",
    "def prep_filt_sfb2d(g0_col, g1_col, g0_row=None, g1_row=None, device=None):\n",
    "    g0_col, g1_col = prep_filt_sfb1d(g0_col, g1_col, device)\n",
    "    if g0_row is None:\n",
    "        g0_row, g1_row = g0_col, g1_col\n",
    "    else:\n",
    "        g0_row, g1_row = prep_filt_sfb1d(g0_row, g1_row, device)\n",
    "\n",
    "    g0_col = g0_col.reshape((1, 1, -1, 1))\n",
    "    g1_col = g1_col.reshape((1, 1, -1, 1))\n",
    "    g0_row = g0_row.reshape((1, 1, 1, -1))\n",
    "    g1_row = g1_row.reshape((1, 1, 1, -1))\n",
    "\n",
    "    return g0_col, g1_col, g0_row, g1_row\n",
    "\n",
    "def sfb2d(ll, lh, hl, hh, filts):\n",
    "    tensorize = [not isinstance(x, torch.Tensor) for x in filts]\n",
    "    if len(filts) == 2:\n",
    "        g0, g1 = filts\n",
    "        if True in tensorize:\n",
    "            g0_col, g1_col, g0_row, g1_row = prep_filt_sfb2d(g0, g1)\n",
    "        else:\n",
    "            g0_col = g0\n",
    "            g0_row = g0.transpose(2,3)\n",
    "            g1_col = g1\n",
    "            g1_row = g1.transpose(2,3)\n",
    "    elif len(filts) == 4:\n",
    "        if True in tensorize:\n",
    "            g0_col, g1_col, g0_row, g1_row = prep_filt_sfb2d(*filts)\n",
    "        else:\n",
    "            g0_col, g1_col, g0_row, g1_row = filts\n",
    "    else:\n",
    "        raise ValueError(\"Unknown form for input filts\")\n",
    "\n",
    "    lo = sfb1d(ll, lh, g0_col, g1_col, dim=2)\n",
    "    hi = sfb1d(hl, hh, g0_col, g1_col, dim=2)\n",
    "    y = sfb1d(lo, hi, g0_row, g1_row, dim=3)\n",
    "\n",
    "    return y\n",
    "        \n",
    "class SFB2D(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, low, highs, g0_row, g1_row, g0_col, g1_col):\n",
    "        ctx.save_for_backward(g0_row, g1_row, g0_col, g1_col)\n",
    "\n",
    "        lh, hl, hh = torch.unbind(highs, dim=2)\n",
    "        lo = sfb1d(low, lh, g0_col, g1_col, dim=2)\n",
    "        hi = sfb1d(hl, hh, g0_col, g1_col, dim=2)\n",
    "        y = sfb1d(lo, hi, g0_row, g1_row, dim=3)\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, dy):\n",
    "        dlow, dhigh = None, None\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            g0_row, g1_row, g0_col, g1_col = ctx.saved_tensors\n",
    "            dx = afb1d(dy, g0_row, g1_row, dim=3)\n",
    "            dx = afb1d(dx, g0_col, g1_col, dim=2)\n",
    "            s = dx.shape\n",
    "            dx = dx.reshape(s[0], -1, 4, s[-2], s[-1])\n",
    "            dlow = dx[:,:,0].contiguous()\n",
    "            dhigh = dx[:,:,1:].contiguous()\n",
    "        return dlow, dhigh, None, None, None, None, None\n",
    "\n",
    "class DWT2DForward(nn.Module):\n",
    "    def __init__(self, J=1, wave='db1'):\n",
    "        super().__init__()\n",
    "        if isinstance(wave, str):\n",
    "            wave = pywt.Wavelet(wave)\n",
    "        if isinstance(wave, pywt.Wavelet):\n",
    "            h0_col, h1_col = wave.dec_lo, wave.dec_hi\n",
    "            h0_row, h1_row = h0_col, h1_col\n",
    "        else:\n",
    "            if len(wave) == 2:\n",
    "                h0_col, h1_col = wave[0], wave[1]\n",
    "                h0_row, h1_row = h0_col, h1_col\n",
    "            elif len(wave) == 4:\n",
    "                h0_col, h1_col = wave[0], wave[1]\n",
    "                h0_row, h1_row = wave[2], wave[3]\n",
    "        filts = prep_filt_afb2d(h0_col, h1_col, h0_row, h1_row)\n",
    "        self.register_buffer('h0_col', filts[0])\n",
    "        self.register_buffer('h1_col', filts[1])\n",
    "        self.register_buffer('h0_row', filts[2])\n",
    "        self.register_buffer('h1_row', filts[3])\n",
    "        self.J = J\n",
    "\n",
    "    def forward(self, x):\n",
    "        yh = []\n",
    "        ll = x\n",
    "        for j in range(self.J):\n",
    "            ll, high = AFB2D.apply(\n",
    "                ll, self.h0_col, self.h1_col, self.h0_row, self.h1_row)\n",
    "            yh.append(high)\n",
    "        return ll, yh\n",
    "\n",
    "class WPT2D(torch.nn.Module):\n",
    "    def __init__(self, wt=DWT2DForward(wave='bior4.4'), J=4):\n",
    "        super().__init__()\n",
    "        self.wt  = wt\n",
    "        self.J = J\n",
    "    def analysis_one_level(self,x):\n",
    "        L, H = self.wt(x)\n",
    "        X = torch.cat([L.unsqueeze(2),H[0]],dim=2)\n",
    "        X = einops.rearrange(X, 'b c f h w -> b (c f) h w')\n",
    "        return X\n",
    "    def wavelet_analysis(self,x,J):\n",
    "        for _ in range(J):\n",
    "            x = self.analysis_one_level(x)\n",
    "        return x\n",
    "    def forward(self, x):\n",
    "        return self.wavelet_analysis(x,J=self.J)\n",
    "\n",
    "class DWT2DInverse(nn.Module):\n",
    "    def __init__(self, wave='db1'):\n",
    "        super().__init__()\n",
    "        if isinstance(wave, str):\n",
    "            wave = pywt.Wavelet(wave)\n",
    "        if isinstance(wave, pywt.Wavelet):\n",
    "            g0_col, g1_col = wave.rec_lo, wave.rec_hi\n",
    "            g0_row, g1_row = g0_col, g1_col\n",
    "        else:\n",
    "            if len(wave) == 2:\n",
    "                g0_col, g1_col = wave[0], wave[1]\n",
    "                g0_row, g1_row = g0_col, g1_col\n",
    "            elif len(wave) == 4:\n",
    "                g0_col, g1_col = wave[0], wave[1]\n",
    "                g0_row, g1_row = wave[2], wave[3]\n",
    "        filts = prep_filt_sfb2d(g0_col, g1_col, g0_row, g1_row)\n",
    "        self.register_buffer('g0_col', filts[0])\n",
    "        self.register_buffer('g1_col', filts[1])\n",
    "        self.register_buffer('g0_row', filts[2])\n",
    "        self.register_buffer('g1_row', filts[3])\n",
    "\n",
    "    def forward(self, coeffs):\n",
    "        yl, yh = coeffs\n",
    "        ll = yl\n",
    "        for h in yh[::-1]:\n",
    "            if h is None:\n",
    "                h = torch.zeros(ll.shape[0], ll.shape[1], 3, ll.shape[-2], ll.shape[-1], device=ll.device)\n",
    "            if ll.shape[-2] > h.shape[-2]:\n",
    "                ll = ll[...,:-1,:]\n",
    "            if ll.shape[-1] > h.shape[-1]:\n",
    "                ll = ll[...,:-1]\n",
    "            ll = SFB2D.apply(ll, h, self.g0_col, self.g1_col, self.g0_row, self.g1_row)\n",
    "        return ll\n",
    "\n",
    "class IWPT2D(torch.nn.Module):\n",
    "    def __init__(self, iwt=DWT2DInverse(wave='bior4.4'), J=4):\n",
    "        super().__init__()\n",
    "        self.iwt  = iwt\n",
    "        self.J = J\n",
    "    def synthesis_one_level(self,X):\n",
    "        X = einops.rearrange(X, 'b (c f) h w -> b c f h w', f=4)\n",
    "        L, H = torch.split(X, [1, 3], dim=2)\n",
    "        L = L.squeeze(2)\n",
    "        H = [H]\n",
    "        y = self.iwt((L, H))\n",
    "        return y\n",
    "    def wavelet_synthesis(self,x,J):\n",
    "        for _ in range(J):\n",
    "            x = self.synthesis_one_level(x)\n",
    "        return x\n",
    "    def forward(self, x):\n",
    "        return self.wavelet_synthesis(x,J=self.J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de33e550-8c4e-439c-b8e8-a78c12a097a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2d = torch.randn(2, 3, 64, 64)\n",
    "wt2d = DWT2DForward(wave='bior4.4')\n",
    "wpt2d = WPT2D(wt=wt2d, J=3)\n",
    "iwt2d = DWT2DInverse(wave='bior4.4')\n",
    "iwpt2d = IWPT2D(iwt=iwt2d, J=3)\n",
    "with torch.no_grad():\n",
    "    X2d = wpt2d(x2d)\n",
    "    xhat2d = iwpt2d(X2d)\n",
    "assert (xhat2d - x2d).abs().max() < 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2446bac8-ddfc-46bc-9f95-bc75df30779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll(x, n, dim, make_even=False):\n",
    "    if n < 0:\n",
    "        n = x.shape[dim] + n\n",
    "    if make_even and x.shape[dim] % 2 == 1:\n",
    "        end = 1\n",
    "    else:\n",
    "        end = 0\n",
    "    if dim == 0:\n",
    "        return torch.cat((x[-n:], x[:-n+end]), dim=0)\n",
    "    elif dim == 1:\n",
    "        return torch.cat((x[:,-n:], x[:,:-n+end]), dim=1)\n",
    "    elif dim == 2:\n",
    "        return torch.cat((x[:,:,-n:], x[:,:,:-n+end]), dim=2)\n",
    "    elif dim == 3:\n",
    "        return torch.cat((x[:,:,:,-n:], x[:,:,:,:-n+end]), dim=3)\n",
    "    elif dim == 4:\n",
    "        return torch.cat((x[:,:,:,:,-n:], x[:,:,:,:,:-n+end]), dim=4)\n",
    "    else:\n",
    "        raise ValueError(\"Dimension out of range\")\n",
    "\n",
    "def prep_filt_afb3d(h0_d, h1_d, h0_h=None, h1_h=None, h0_w=None, h1_w=None, device=None):\n",
    "    # Prepare depth filters\n",
    "    h0_d, h1_d = prep_filt_afb1d(h0_d, h1_d, device)\n",
    "    # If height filters are not provided, use depth filters\n",
    "    if h0_h is None:\n",
    "        h0_h, h1_h = h0_d, h1_d\n",
    "    else:\n",
    "        h0_h, h1_h = prep_filt_afb1d(h0_h, h1_h, device)\n",
    "    # If width filters are not provided, use height filters\n",
    "    if h0_w is None:\n",
    "        h0_w, h1_w = h0_h, h1_h\n",
    "    else:\n",
    "        h0_w, h1_w = prep_filt_afb1d(h0_w, h1_w, device)\n",
    "    \n",
    "    # Reshape filters for 3D convolution: (out_channels, in_channels/groups, D, H, W)\n",
    "    h0_d = h0_d.reshape(1, 1, -1, 1, 1)  # Depth filter\n",
    "    h1_d = h1_d.reshape(1, 1, -1, 1, 1)\n",
    "    h0_h = h0_h.reshape(1, 1, 1, -1, 1)  # Height filter\n",
    "    h1_h = h1_h.reshape(1, 1, 1, -1, 1)\n",
    "    h0_w = h0_w.reshape(1, 1, 1, 1, -1)  # Width filter\n",
    "    h1_w = h1_w.reshape(1, 1, 1, 1, -1)\n",
    "    return h0_d, h1_d, h0_h, h1_h, h0_w, h1_w\n",
    "\n",
    "def afb1d_3d(x, h0, h1, dim=-1):\n",
    "    assert x.ndim == 5, \"Input must be 5D (N, C, D, H, W)\"\n",
    "    assert dim in [2, 3, 4], \"dim must be 2 (D), 3 (H), or 4 (W)\"\n",
    "    \n",
    "    C = x.shape[1]\n",
    "    N = x.shape[dim]\n",
    "    L = h0.numel()\n",
    "    L2 = L // 2\n",
    "    \n",
    "    # Prepare filter shapes based on dimension\n",
    "    if dim == 2:  # Depth\n",
    "        h0 = h0.view(1, 1, L, 1, 1)\n",
    "        h1 = h1.view(1, 1, L, 1, 1)\n",
    "        padding = (L-1, 0, 0)  # padD, padH, padW\n",
    "        stride = (2, 1, 1)\n",
    "    elif dim == 3:  # Height\n",
    "        h0 = h0.view(1, 1, 1, L, 1)\n",
    "        h1 = h1.view(1, 1, 1, L, 1)\n",
    "        padding = (0, L-1, 0)\n",
    "        stride = (1, 2, 1)\n",
    "    elif dim == 4:  # Width\n",
    "        h0 = h0.view(1, 1, 1, 1, L)\n",
    "        h1 = h1.view(1, 1, 1, 1, L)\n",
    "        padding = (0, 0, L-1)\n",
    "        stride = (1, 1, 2)\n",
    "    \n",
    "    # Stack filters for each channel\n",
    "    h = torch.cat([h0, h1] * C, dim=0)  # Shape: (2*C, 1, kernel_D, kernel_H, kernel_W)\n",
    "    \n",
    "    # Pad to handle odd lengths\n",
    "    if N % 2 == 1:\n",
    "        if dim == 2:\n",
    "            x = torch.cat((x, x[:, :, -1:, :, :]), dim=2)\n",
    "        elif dim == 3:\n",
    "            x = torch.cat((x, x[:, :, :, -1:, :]), dim=3)\n",
    "        elif dim == 4:\n",
    "            x = torch.cat((x, x[:, :, :, :, -1:]), dim=4)\n",
    "        N += 1\n",
    "    \n",
    "    # Roll the input to align with filter\n",
    "    x = torch.roll(x, -L2, dims=dim)\n",
    "    \n",
    "    # Apply 3D convolution with asymmetric padding\n",
    "    lohi = F.conv3d(x, h, stride=stride, padding=padding, groups=C)\n",
    "    \n",
    "    # Handle overlap if output is larger than N//2\n",
    "    N2 = N // 2\n",
    "    if lohi.shape[dim] > N2:\n",
    "        if dim == 2:\n",
    "            lohi[:, :, :L2, :, :] += lohi[:, :, N2:N2+L2, :, :]\n",
    "            lohi = lohi[:, :, :N2, :, :]\n",
    "        elif dim == 3:\n",
    "            lohi[:, :, :, :L2, :] += lohi[:, :, :, N2:N2+L2, :]\n",
    "            lohi = lohi[:, :, :, :N2, :]\n",
    "        elif dim == 4:\n",
    "            lohi[:, :, :, :, :L2] += lohi[:, :, :, :, N2:N2+L2]\n",
    "            lohi = lohi[:, :, :, :, :N2]\n",
    "    \n",
    "    return lohi\n",
    "\n",
    "def afb3d(x, filts):\n",
    "    tensorize = [not isinstance(f, torch.Tensor) for f in filts]\n",
    "    if len(filts) == 2:\n",
    "        h0, h1 = filts\n",
    "        if True in tensorize:\n",
    "            h0_d, h1_d, h0_h, h1_h, h0_w, h1_w = prep_filt_afb3d(h0, h1, device=x.device)\n",
    "        else:\n",
    "            h0_d = h0.transpose(2, 4)\n",
    "            h1_d = h1.transpose(2, 4)\n",
    "            h0_h = h0.transpose(2, 3)\n",
    "            h1_h = h1.transpose(2, 3)\n",
    "            h0_w = h0\n",
    "            h1_w = h1\n",
    "    elif len(filts) == 6:\n",
    "        if True in tensorize:\n",
    "            h0_d, h1_d, h0_h, h1_h, h0_w, h1_w = prep_filt_afb3d(*filts, device=x.device)\n",
    "        else:\n",
    "            h0_d, h1_d, h0_h, h1_h, h0_w, h1_w = filts\n",
    "    else:\n",
    "        raise ValueError(\"filts must be length 2 or 6\")\n",
    "    \n",
    "    # Apply decomposition sequentially\n",
    "    lohi_w = afb1d_3d(x, h0_w, h1_w, dim=4)      # (N, 2*C, D, H, W/2)\n",
    "    lohi_hw = afb1d_3d(lohi_w, h0_h, h1_h, dim=3) # (N, 4*C, D, H/2, W/2)\n",
    "    y = afb1d_3d(lohi_hw, h0_d, h1_d, dim=2)     # (N, 8*C, D/2, H/2, W/2)\n",
    "    \n",
    "    return y\n",
    "\n",
    "class DWT3DForward(nn.Module):\n",
    "    def __init__(self, J=1, wave='db1'):\n",
    "        super().__init__()\n",
    "        self.J = J\n",
    "        if isinstance(wave, str):\n",
    "            wave = pywt.Wavelet(wave)\n",
    "        if isinstance(wave, pywt.Wavelet):\n",
    "            h0, h1 = wave.dec_lo, wave.dec_hi\n",
    "            h0_d, h1_d = h0, h1\n",
    "            h0_h, h1_h = h0, h1\n",
    "            h0_w, h1_w = h0, h1\n",
    "        else:\n",
    "            if len(wave) == 2:\n",
    "                h0, h1 = wave[0], wave[1]\n",
    "                h0_d, h1_d = h0, h1\n",
    "                h0_h, h1_h = h0, h1\n",
    "                h0_w, h1_w = h0, h1\n",
    "            elif len(wave) == 6:\n",
    "                h0_d, h1_d, h0_h, h1_h, h0_w, h1_w = wave\n",
    "            else:\n",
    "                raise ValueError(\"wave must be a string, pywt.Wavelet, or tuple of 2 or 6 filters\")\n",
    "        \n",
    "        filts = prep_filt_afb3d(h0_d, h1_d, h0_h, h1_h, h0_w, h1_w)\n",
    "        self.register_buffer('h0_d', filts[0])\n",
    "        self.register_buffer('h1_d', filts[1])\n",
    "        self.register_buffer('h0_h', filts[2])\n",
    "        self.register_buffer('h1_h', filts[3])\n",
    "        self.register_buffer('h0_w', filts[4])\n",
    "        self.register_buffer('h1_w', filts[5])\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert x.ndim == 5, \"Input must be 5D (N, C, D, H, W)\"\n",
    "        yhs = []\n",
    "        ll = x\n",
    "        filts = (self.h0_d, self.h1_d, self.h0_h, self.h1_h, self.h0_w, self.h1_w)\n",
    "        for j in range(self.J):\n",
    "            y = afb3d(ll, filts)  # (N, 8*C, D/2^j, H/2^j, W/2^j)\n",
    "            C = ll.shape[1]\n",
    "            ll = y[:, :C]         # LLL subband\n",
    "            high = y[:, C:]       # 7 high-pass subbands\n",
    "            yhs.append(high)\n",
    "        return ll, yhs\n",
    "\n",
    "\n",
    "class WPT3D(nn.Module):\n",
    "    def __init__(self, wt=None, J=4, wave='db1'):\n",
    "        super().__init__()\n",
    "        self.J = J\n",
    "        if wt is None:\n",
    "            self.wt = DWT3DForward(J=1, wave=wave)\n",
    "        else:\n",
    "            self.wt = wt\n",
    "\n",
    "    def analysis_one_level(self, x):\n",
    "        L, H = self.wt(x)\n",
    "        # Concatenate low and high subbands: 8 subbands total\n",
    "        X = torch.cat([L.unsqueeze(2), H[0].view(L.shape[0], -1, 7, L.shape[2], L.shape[3], L.shape[4])], dim=2)\n",
    "        X = einops.rearrange(X, 'b c f d h w -> b (c f) d h w')\n",
    "        return X\n",
    "\n",
    "    def forward(self, x):\n",
    "        for _ in range(self.J):\n",
    "            x = self.analysis_one_level(x)\n",
    "        return x\n",
    "\n",
    "def sfb1d_3d(lo, hi, g0, g1, dim=-1):\n",
    "    assert lo.ndim == 5 and hi.ndim == 5, \"Inputs must be 5D (N, C, D, H, W)\"\n",
    "    assert lo.shape == hi.shape, \"Low and high subbands must have the same shape\"\n",
    "    assert dim in [2, 3, 4], \"dim must be 2 (D), 3 (H), or 4 (W)\"\n",
    "\n",
    "    C = lo.shape[1]\n",
    "    d = dim % 5\n",
    "    N = 2 * lo.shape[d]  # Output size after upsampling\n",
    "    L = g0.numel() if isinstance(g0, torch.Tensor) else len(g0)\n",
    "    L2 = L // 2\n",
    "\n",
    "    # Convert filters to tensors if necessary\n",
    "    if not isinstance(g0, torch.Tensor):\n",
    "        g0 = torch.tensor(np.array(g0).ravel(), dtype=torch.float, device=lo.device)\n",
    "    if not isinstance(g1, torch.Tensor):\n",
    "        g1 = torch.tensor(np.array(g1).ravel(), dtype=torch.float, device=hi.device)\n",
    "\n",
    "    # Reshape filters based on dimension\n",
    "    if d == 2:  # Depth\n",
    "        g0 = g0.reshape(1, 1, -1, 1, 1)\n",
    "        g1 = g1.reshape(1, 1, -1, 1, 1)\n",
    "        stride = (2, 1, 1)\n",
    "    elif d == 3:  # Height\n",
    "        g0 = g0.reshape(1, 1, 1, -1, 1)\n",
    "        g1 = g1.reshape(1, 1, 1, -1, 1)\n",
    "        stride = (1, 2, 1)\n",
    "    elif d == 4:  # Width\n",
    "        g0 = g0.reshape(1, 1, 1, 1, -1)\n",
    "        g1 = g1.reshape(1, 1, 1, 1, -1)\n",
    "        stride = (1, 1, 2)\n",
    "\n",
    "    # Repeat filters for each channel\n",
    "    g0 = g0.repeat(C, 1, 1, 1, 1)\n",
    "    g1 = g1.repeat(C, 1, 1, 1, 1)\n",
    "\n",
    "    # Apply transposed convolution (upsampling)\n",
    "    y = F.conv_transpose3d(lo, g0, stride=stride, groups=C) + \\\n",
    "        F.conv_transpose3d(hi, g1, stride=stride, groups=C)\n",
    "\n",
    "    # Handle boundary overlap\n",
    "    if y.shape[d] > N:\n",
    "        idx = [slice(None)] * 5\n",
    "        idx[d] = slice(None, L-2)\n",
    "        idx2 = [slice(None)] * 5\n",
    "        idx2[d] = slice(N, N + L-2)\n",
    "        y = y.clone()  # Avoid in-place modification\n",
    "        y[tuple(idx)] = y[tuple(idx)] + y[tuple(idx2)]\n",
    "        idx[d] = slice(None, N)\n",
    "        y = y[tuple(idx)]\n",
    "\n",
    "    # Phase adjustment\n",
    "    y = roll(y, 1 - L2, dim=d)\n",
    "\n",
    "    return y\n",
    "\n",
    "def sfb3d(y, filts):\n",
    "    assert y.ndim == 5 and y.shape[1] % 8 == 0, \"Input must be (N, 8*C, D/2, H/2, W/2)\"\n",
    "    C = y.shape[1] // 8\n",
    "    g0_d, g1_d, g0_h, g1_h, g0_w, g1_w = filts\n",
    "\n",
    "    # Extract the eight subbands for each original channel\n",
    "    y0 = y[:, 0::8, :, :, :]  # LLL: lo_d lo_h lo_w\n",
    "    y1 = y[:, 1::8, :, :, :]  # HLL: hi_d lo_h lo_w\n",
    "    y2 = y[:, 2::8, :, :, :]  # LHL: lo_d hi_h lo_w\n",
    "    y3 = y[:, 3::8, :, :, :]  # HHL: hi_d hi_h lo_w\n",
    "    y4 = y[:, 4::8, :, :, :]  # LLH: lo_d lo_h hi_w\n",
    "    y5 = y[:, 5::8, :, :, :]  # HLH: hi_d lo_h hi_w\n",
    "    y6 = y[:, 6::8, :, :, :]  # LHH: lo_d hi_h hi_w\n",
    "    y7 = y[:, 7::8, :, :, :]  # HHH: hi_d hi_h hi_w\n",
    "\n",
    "    # Step 1: Reconstruct along depth\n",
    "    t0 = sfb1d_3d(y0, y1, g0_d, g1_d, dim=2)  # lo_h lo_w (N, C, D, H/2, W/2)\n",
    "    t1 = sfb1d_3d(y2, y3, g0_d, g1_d, dim=2)  # hi_h lo_w\n",
    "    t2 = sfb1d_3d(y4, y5, g0_d, g1_d, dim=2)  # lo_h hi_w\n",
    "    t3 = sfb1d_3d(y6, y7, g0_d, g1_d, dim=2)  # hi_h hi_w\n",
    "\n",
    "    # Step 2: Reconstruct along height\n",
    "    u0 = sfb1d_3d(t0, t1, g0_h, g1_h, dim=3)  # lo_w (N, C, D, H, W/2)\n",
    "    u1 = sfb1d_3d(t2, t3, g0_h, g1_h, dim=3)  # hi_w\n",
    "\n",
    "    # Step 3: Reconstruct along width\n",
    "    y_rec = sfb1d_3d(u0, u1, g0_w, g1_w, dim=4)  # (N, C, D, H, W)\n",
    "\n",
    "    return y_rec\n",
    "\n",
    "class DWT3DInverse(nn.Module):\n",
    "    def __init__(self, wave='db1'):\n",
    "        super().__init__()\n",
    "        # Filter initialization\n",
    "        if isinstance(wave, str):\n",
    "            wave = pywt.Wavelet(wave)\n",
    "        if isinstance(wave, pywt.Wavelet):\n",
    "            g0, g1 = wave.rec_lo, wave.rec_hi\n",
    "            g0_d, g1_d = g0, g1\n",
    "            g0_h, g1_h = g0, g1\n",
    "            g0_w, g1_w = g0, g1\n",
    "        else:\n",
    "            if len(wave) == 2:\n",
    "                g0, g1 = wave[0], wave[1]\n",
    "                g0_d, g1_d = g0, g1\n",
    "                g0_h, g1_h = g0, g1\n",
    "                g0_w, g1_w = g0, g1\n",
    "            elif len(wave) == 6:\n",
    "                g0_d, g1_d, g0_h, g1_h, g0_w, g1_w = wave\n",
    "            else:\n",
    "                raise ValueError(\"wave must be a string, pywt.Wavelet, or tuple of 2 or 6 filters\")\n",
    "\n",
    "        # Register filters as buffers\n",
    "        self.register_buffer('g0_d', torch.tensor(g0_d, dtype=torch.float).reshape(1, 1, -1, 1, 1))\n",
    "        self.register_buffer('g1_d', torch.tensor(g1_d, dtype=torch.float).reshape(1, 1, -1, 1, 1))\n",
    "        self.register_buffer('g0_h', torch.tensor(g0_h, dtype=torch.float).reshape(1, 1, 1, -1, 1))\n",
    "        self.register_buffer('g1_h', torch.tensor(g1_h, dtype=torch.float).reshape(1, 1, 1, -1, 1))\n",
    "        self.register_buffer('g0_w', torch.tensor(g0_w, dtype=torch.float).reshape(1, 1, 1, 1, -1))\n",
    "        self.register_buffer('g1_w', torch.tensor(g1_w, dtype=torch.float).reshape(1, 1, 1, 1, -1))\n",
    "\n",
    "    def forward(self, coeffs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            coeffs (tuple): (yl, yh) where yl is (N, C, D/2, H/2, W/2) and\n",
    "                           yh is a list with high subbands (N, 7*C, D/2, H/2, W/2)\n",
    "        Returns:\n",
    "            Tensor: Reconstructed signal (N, C, D, H, W)\n",
    "        \"\"\"\n",
    "        yl, yh = coeffs\n",
    "        ll = yl\n",
    "\n",
    "        filts = (self.g0_d, self.g1_d, self.g0_h, self.g1_h, self.g0_w, self.g1_w)\n",
    "        for h in yh[::-1]:\n",
    "            if h is None:\n",
    "                h = torch.zeros(ll.shape[0], 7 * ll.shape[1], ll.shape[2],\n",
    "                                ll.shape[3], ll.shape[4], device=ll.device)\n",
    "            # Ensure spatial dimensions match by trimming if necessary\n",
    "            dims = [-3, -2, -1]  # D, H, W\n",
    "            for d in dims:\n",
    "                if ll.shape[d] > h.shape[d]:\n",
    "                    ll = ll.narrow(d, 0, h.shape[d])\n",
    "            y_all = torch.cat([ll, h], dim=1)  # (N, 8*C, D/2, H/2, W/2)\n",
    "            ll = sfb3d(y_all, filts)\n",
    "\n",
    "        return ll\n",
    "\n",
    "class IWPT3D(nn.Module):\n",
    "    def __init__(self, iwt=None, J=4, wave='db1'):\n",
    "        super().__init__()\n",
    "        self.J = J\n",
    "        if iwt is None:\n",
    "            self.iwt = DWT3DInverse(wave=wave)\n",
    "        else:\n",
    "            self.iwt = iwt\n",
    "\n",
    "    def synthesis_one_level(self, X):\n",
    "        X = einops.rearrange(X, 'b (c f) d h w -> b c f d h w', f=8)\n",
    "        L, H = torch.split(X, [1, 7], dim=2)  # L: (N, C, 1, D/2, H/2, W/2), H: (N, C, 7, D/2, H/2, W/2)\n",
    "        L = L.squeeze(2)  # (N, C, D/2, H/2, W/2)\n",
    "        H = einops.rearrange(H, 'b c f d h w -> b (c f) d h w')  # (N, 7*C, D/2, H/2, W/2)\n",
    "        y = self.iwt((L, [H]))\n",
    "        return y\n",
    "\n",
    "    def wavelet_synthesis(self, x, J):\n",
    "        for _ in range(J):\n",
    "            x = self.synthesis_one_level(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.wavelet_synthesis(x, self.J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38468844-0c26-4e3e-b11f-2269770c0889",
   "metadata": {},
   "outputs": [],
   "source": [
    "x3d = torch.randn(2, 3, 16, 16, 16)\n",
    "wt3d = DWT3DForward(wave='bior4.4')\n",
    "wpt3d = WPT3D(wt=wt3d,J=1)\n",
    "iwt3d = DWT3DInverse(wave='bior4.4')\n",
    "iwpt3d = IWPT3D(iwt=iwt3d, J=1)\n",
    "with torch.no_grad():\n",
    "    X3d = wpt3d(x3d)\n",
    "    xhat3d = iwpt3d(X3d)\n",
    "assert (xhat3d - x3d).abs().max() < 1e-5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
