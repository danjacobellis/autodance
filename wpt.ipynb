{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a6ad368-7205-4a92-9f5c-7f7e7304ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pywt\n",
    "import einops\n",
    "from torch.autograd import Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2cd2c25-f1b0-48d7-b612-16c8facda1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll(x, n, dim, make_even=False):\n",
    "    if n < 0:\n",
    "        n = x.shape[dim] + n\n",
    "\n",
    "    if make_even and x.shape[dim] % 2 == 1:\n",
    "        end = 1\n",
    "    else:\n",
    "        end = 0\n",
    "\n",
    "    if dim == 0:\n",
    "        return torch.cat((x[-n:], x[:-n+end]), dim=0)\n",
    "    elif dim == 1:\n",
    "        return torch.cat((x[:,-n:], x[:,:-n+end]), dim=1)\n",
    "    elif dim == 2 or dim == -2:\n",
    "        return torch.cat((x[:,:,-n:], x[:,:,:-n+end]), dim=2)\n",
    "    elif dim == 3 or dim == -1:\n",
    "        return torch.cat((x[:,:,:,-n:], x[:,:,:,:-n+end]), dim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bcea4a5-e98a-433f-a641-b77ad23af179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_filt_afb1d(h0, h1, device=None):\n",
    "    h0 = np.array(h0[::-1]).ravel()\n",
    "    h1 = np.array(h1[::-1]).ravel()\n",
    "    t = torch.get_default_dtype()\n",
    "    h0 = torch.tensor(h0, device=device, dtype=t).reshape((1, 1, -1))\n",
    "    h1 = torch.tensor(h1, device=device, dtype=t).reshape((1, 1, -1))\n",
    "    return h0, h1\n",
    "\n",
    "def afb1d(x, h0, h1, dim=-1):\n",
    "    C = x.shape[1]\n",
    "    # Convert the dim to positive\n",
    "    d = dim % 4\n",
    "    s = (2, 1) if d == 2 else (1, 2)\n",
    "    N = x.shape[d]\n",
    "    # If h0, h1 are not tensors, make them. If they are, then assume that they\n",
    "    # are in the right order\n",
    "    if not isinstance(h0, torch.Tensor):\n",
    "        h0 = torch.tensor(np.copy(np.array(h0).ravel()[::-1]),\n",
    "                          dtype=torch.float, device=x.device)\n",
    "    if not isinstance(h1, torch.Tensor):\n",
    "        h1 = torch.tensor(np.copy(np.array(h1).ravel()[::-1]),\n",
    "                          dtype=torch.float, device=x.device)\n",
    "    L = h0.numel()\n",
    "    L2 = L // 2\n",
    "    shape = [1,1,1,1]\n",
    "    shape[d] = L\n",
    "    # If h aren't in the right shape, make them so\n",
    "    if h0.shape != tuple(shape):\n",
    "        h0 = h0.reshape(*shape)\n",
    "    if h1.shape != tuple(shape):\n",
    "        h1 = h1.reshape(*shape)\n",
    "    h = torch.cat([h0, h1] * C, dim=0)\n",
    "\n",
    "    if x.shape[dim] % 2 == 1:\n",
    "        if d == 2:\n",
    "            x = torch.cat((x, x[:,:,-1:]), dim=2)\n",
    "        else:\n",
    "            x = torch.cat((x, x[:,:,:,-1:]), dim=3)\n",
    "        N += 1\n",
    "    x = roll(x, -L2, dim=d)\n",
    "    pad = (L-1, 0) if d == 2 else (0, L-1)\n",
    "    lohi = F.conv2d(x, h, padding=pad, stride=s, groups=C)\n",
    "    N2 = N//2\n",
    "    if d == 2:\n",
    "        lohi[:,:,:L2] = lohi[:,:,:L2] + lohi[:,:,N2:N2+L2]\n",
    "        lohi = lohi[:,:,:N2]\n",
    "    else:\n",
    "        lohi[:,:,:,:L2] = lohi[:,:,:,:L2] + lohi[:,:,:,N2:N2+L2]\n",
    "        lohi = lohi[:,:,:,:N2]\n",
    "\n",
    "    return lohi\n",
    "        \n",
    "class AFB1D(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, h0, h1):\n",
    "\n",
    "        # Make inputs 4d\n",
    "        x = x[:, :, None, :]\n",
    "        h0 = h0[:, :, None, :]\n",
    "        h1 = h1[:, :, None, :]\n",
    "\n",
    "        # Save for backwards\n",
    "        ctx.save_for_backward(h0, h1)\n",
    "        ctx.shape = x.shape[3]\n",
    "\n",
    "        lohi = afb1d(x, h0, h1, dim=3)\n",
    "        x0 = lohi[:, ::2, 0].contiguous()\n",
    "        x1 = lohi[:, 1::2, 0].contiguous()\n",
    "        return x0, x1\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, dx0, dx1):\n",
    "        dx = None\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            h0, h1 = ctx.saved_tensors\n",
    "\n",
    "            # Make grads 4d\n",
    "            dx0 = dx0[:, :, None, :]\n",
    "            dx1 = dx1[:, :, None, :]\n",
    "\n",
    "            dx = sfb1d(dx0, dx1, h0, h1, dim=3)[:, :, 0]\n",
    "\n",
    "            # Check for odd input\n",
    "            if dx.shape[2] > ctx.shape:\n",
    "                dx = dx[:, :, :ctx.shape]\n",
    "\n",
    "        return dx, None, None, None, None, None\n",
    "\n",
    "def prep_filt_sfb1d(g0, g1, device=None):\n",
    "    g0 = np.array(g0).ravel()\n",
    "    g1 = np.array(g1).ravel()\n",
    "    t = torch.get_default_dtype()\n",
    "    g0 = torch.tensor(g0, device=device, dtype=t).reshape((1, 1, -1))\n",
    "    g1 = torch.tensor(g1, device=device, dtype=t).reshape((1, 1, -1))\n",
    "\n",
    "    return g0, g1\n",
    "\n",
    "def sfb1d(lo, hi, g0, g1, dim=-1):\n",
    "    C = lo.shape[1]\n",
    "    d = dim % 4\n",
    "    if not isinstance(g0, torch.Tensor):\n",
    "        g0 = torch.tensor(np.copy(np.array(g0).ravel()),\n",
    "                          dtype=torch.float, device=lo.device)\n",
    "    if not isinstance(g1, torch.Tensor):\n",
    "        g1 = torch.tensor(np.copy(np.array(g1).ravel()),\n",
    "                          dtype=torch.float, device=lo.device)\n",
    "    L = g0.numel()\n",
    "    shape = [1,1,1,1]\n",
    "    shape[d] = L\n",
    "    N = 2*lo.shape[d]\n",
    "    # If g aren't in the right shape, make them so\n",
    "    if g0.shape != tuple(shape):\n",
    "        g0 = g0.reshape(*shape)\n",
    "    if g1.shape != tuple(shape):\n",
    "        g1 = g1.reshape(*shape)\n",
    "\n",
    "    s = (2, 1) if d == 2 else (1,2)\n",
    "    g0 = torch.cat([g0]*C,dim=0)\n",
    "    g1 = torch.cat([g1]*C,dim=0)\n",
    "    y = F.conv_transpose2d(lo, g0, stride=s, groups=C) + \\\n",
    "        F.conv_transpose2d(hi, g1, stride=s, groups=C)\n",
    "    if d == 2:\n",
    "        y[:,:,:L-2] = y[:,:,:L-2] + y[:,:,N:N+L-2]\n",
    "        y = y[:,:,:N]\n",
    "    else:\n",
    "        y[:,:,:,:L-2] = y[:,:,:,:L-2] + y[:,:,:,N:N+L-2]\n",
    "        y = y[:,:,:,:N]\n",
    "    y = roll(y, 1-L//2, dim=dim)\n",
    "\n",
    "    return y\n",
    "\n",
    "class SFB1D(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, low, high, g0, g1):\n",
    "        # Make into a 2d tensor with 1 row\n",
    "        low = low[:, :, None, :]\n",
    "        high = high[:, :, None, :]\n",
    "        g0 = g0[:, :, None, :]\n",
    "        g1 = g1[:, :, None, :]\n",
    "\n",
    "        ctx.save_for_backward(g0, g1)\n",
    "\n",
    "        return sfb1d(low, high, g0, g1, dim=3)[:, :, 0]\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, dy):\n",
    "        dlow, dhigh = None, None\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            g0, g1, = ctx.saved_tensors\n",
    "            dy = dy[:, :, None, :]\n",
    "\n",
    "            dx = afb1d(dy, g0, g1, dim=3)\n",
    "\n",
    "            dlow = dx[:, ::2, 0].contiguous()\n",
    "            dhigh = dx[:, 1::2, 0].contiguous()\n",
    "        return dlow, dhigh, None, None, None, None, None\n",
    "\n",
    "class DWT1DForward(nn.Module):\n",
    "    def __init__(self, J=1, wave='db1'):\n",
    "        super().__init__()\n",
    "        if isinstance(wave, str):\n",
    "            wave = pywt.Wavelet(wave)\n",
    "        if isinstance(wave, pywt.Wavelet):\n",
    "            h0, h1 = wave.dec_lo, wave.dec_hi\n",
    "        else:\n",
    "            assert len(wave) == 2\n",
    "            h0, h1 = wave[0], wave[1]\n",
    "        filts = prep_filt_afb1d(h0, h1)\n",
    "        self.register_buffer('h0', filts[0])\n",
    "        self.register_buffer('h1', filts[1])\n",
    "        self.J = J\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert x.ndim == 3, \"Can only handle 3d inputs (N, C, L)\"\n",
    "        highs = []\n",
    "        x0 = x\n",
    "        for j in range(self.J):\n",
    "            x0, x1 = AFB1D.apply(x0, self.h0, self.h1)\n",
    "            highs.append(x1)\n",
    "        return x0, highs\n",
    "        \n",
    "class WPT1D(torch.nn.Module):\n",
    "    def __init__(self, wt=DWT1DForward(wave='bior4.4'), J=4):\n",
    "        super().__init__()\n",
    "        self.wt = wt\n",
    "        self.J = J\n",
    "\n",
    "    def analysis_one_level(self,x):\n",
    "        L, H = self.wt(x)\n",
    "        X = torch.cat([L.unsqueeze(2),H[0].unsqueeze(2)],dim=2)\n",
    "        X = einops.rearrange(X, 'b c f ℓ -> b (c f) ℓ')\n",
    "        return X\n",
    "\n",
    "    def wavelet_analysis(self, x, J):\n",
    "        for _ in range(J):\n",
    "            x = self.analysis_one_level(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.wavelet_analysis(x, J=self.J)\n",
    "        \n",
    "class DWT1DInverse(nn.Module):\n",
    "    def __init__(self, wave='db1'):\n",
    "        super().__init__()\n",
    "        if isinstance(wave, str):\n",
    "            wave = pywt.Wavelet(wave)\n",
    "        if isinstance(wave, pywt.Wavelet):\n",
    "            g0, g1 = wave.rec_lo, wave.rec_hi\n",
    "        else:\n",
    "            assert len(wave) == 2\n",
    "            g0, g1 = wave[0], wave[1]\n",
    "        filts = prep_filt_sfb1d(g0, g1)\n",
    "        self.register_buffer('g0', filts[0])\n",
    "        self.register_buffer('g1', filts[1])\n",
    "\n",
    "    def forward(self, coeffs):\n",
    "        x0, highs = coeffs\n",
    "        assert x0.ndim == 3, \"Can only handle 3d inputs (N, C, L)\"\n",
    "        for x1 in highs[::-1]:\n",
    "            if x1 is None:\n",
    "                x1 = torch.zeros_like(x0)\n",
    "            if x0.shape[-1] > x1.shape[-1]:\n",
    "                x0 = x0[..., :-1]\n",
    "            x0 = SFB1D.apply(x0, x1, self.g0, self.g1)\n",
    "        return x0\n",
    "\n",
    "class IWPT1D(torch.nn.Module):\n",
    "    def __init__(self, iwt=DWT1DInverse(wave='bior4.4'), J=4):\n",
    "        super().__init__()\n",
    "        self.iwt = iwt\n",
    "        self.J = J\n",
    "\n",
    "    def synthesis_one_level(self, X):\n",
    "        X = einops.rearrange(X, 'b (c f) ℓ -> b c f ℓ', f=2)\n",
    "        L, H = torch.split(X, [1, 1], dim=2)\n",
    "        L = L.squeeze(2)\n",
    "        H = [H.squeeze(2)]\n",
    "        y = self.iwt((L, H))\n",
    "        return y\n",
    "\n",
    "    def wavelet_synthesis(self, x, J):\n",
    "        for _ in range(J):\n",
    "            x = self.synthesis_one_level(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.wavelet_synthesis(x, J=self.J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6465dd31-d2ae-4b5f-872a-501e11457047",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1d = torch.randn(2, 3, 4096)\n",
    "wt1d = DWT1DForward(wave='bior4.4')\n",
    "wpt1d = WPT1D(wt=wt1d, J=3)\n",
    "iwt1d = DWT1DInverse(wave='bior4.4')\n",
    "iwpt1d = IWPT1D(iwt=iwt1d, J=3)\n",
    "with torch.no_grad():\n",
    "    X1d = wpt1d(x1d)\n",
    "    xhat1d = iwpt1d(X1d)\n",
    "assert (xhat1d - x1d).abs().max() < 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a93fb734-9e91-4f20-82cd-265985ebc87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_filt_afb2d(h0_col, h1_col, h0_row=None, h1_row=None, device=None):\n",
    "    h0_col, h1_col = prep_filt_afb1d(h0_col, h1_col, device)\n",
    "    if h0_row is None:\n",
    "        h0_row, h1_row = h0_col, h1_col\n",
    "    else:\n",
    "        h0_row, h1_row = prep_filt_afb1d(h0_row, h1_row, device)\n",
    "\n",
    "    h0_col = h0_col.reshape((1, 1, -1, 1))\n",
    "    h1_col = h1_col.reshape((1, 1, -1, 1))\n",
    "    h0_row = h0_row.reshape((1, 1, 1, -1))\n",
    "    h1_row = h1_row.reshape((1, 1, 1, -1))\n",
    "    return h0_col, h1_col, h0_row, h1_row\n",
    "\n",
    "def afb2d(x, filts):\n",
    "    tensorize = [not isinstance(f, torch.Tensor) for f in filts]\n",
    "    if len(filts) == 2:\n",
    "        h0, h1 = filts\n",
    "        if True in tensorize:\n",
    "            h0_col, h1_col, h0_row, h1_row = prep_filt_afb2d(\n",
    "                h0, h1, device=x.device)\n",
    "        else:\n",
    "            h0_col = h0\n",
    "            h0_row = h0.transpose(2,3)\n",
    "            h1_col = h1\n",
    "            h1_row = h1.transpose(2,3)\n",
    "    elif len(filts) == 4:\n",
    "        if True in tensorize:\n",
    "            h0_col, h1_col, h0_row, h1_row = prep_filt_afb2d(\n",
    "                *filts, device=x.device)\n",
    "        else:\n",
    "            h0_col, h1_col, h0_row, h1_row = filts\n",
    "    else:\n",
    "        raise ValueError(\"Unknown form for input filts\")\n",
    "\n",
    "    lohi = afb1d(x, h0_row, h1_row, dim=3)\n",
    "    y = afb1d(lohi, h0_col, h1_col, dim=2)\n",
    "\n",
    "    return y\n",
    "\n",
    "class AFB2D(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, h0_row, h1_row, h0_col, h1_col):\n",
    "        ctx.save_for_backward(h0_row, h1_row, h0_col, h1_col)\n",
    "        ctx.shape = x.shape[-2:]\n",
    "        lohi = afb1d(x, h0_row, h1_row, dim=3)\n",
    "        y = afb1d(lohi, h0_col, h1_col, dim=2)\n",
    "        s = y.shape\n",
    "        y = y.reshape(s[0], -1, 4, s[-2], s[-1])\n",
    "        low = y[:,:,0].contiguous()\n",
    "        highs = y[:,:,1:].contiguous()\n",
    "        return low, highs\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, low, highs):\n",
    "        dx = None\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            h0_row, h1_row, h0_col, h1_col = ctx.saved_tensors\n",
    "            lh, hl, hh = torch.unbind(highs, dim=2)\n",
    "            lo = sfb1d(low, lh, h0_col, h1_col, dim=2)\n",
    "            hi = sfb1d(hl, hh, h0_col, h1_col, dim=2)\n",
    "            dx = sfb1d(lo, hi, h0_row, h1_row, dim=3)\n",
    "            if dx.shape[-2] > ctx.shape[-2] and dx.shape[-1] > ctx.shape[-1]:\n",
    "                dx = dx[:,:,:ctx.shape[-2], :ctx.shape[-1]]\n",
    "            elif dx.shape[-2] > ctx.shape[-2]:\n",
    "                dx = dx[:,:,:ctx.shape[-2]]\n",
    "            elif dx.shape[-1] > ctx.shape[-1]:\n",
    "                dx = dx[:,:,:,:ctx.shape[-1]]\n",
    "        return dx, None, None, None, None, None\n",
    "\n",
    "def prep_filt_sfb2d(g0_col, g1_col, g0_row=None, g1_row=None, device=None):\n",
    "    g0_col, g1_col = prep_filt_sfb1d(g0_col, g1_col, device)\n",
    "    if g0_row is None:\n",
    "        g0_row, g1_row = g0_col, g1_col\n",
    "    else:\n",
    "        g0_row, g1_row = prep_filt_sfb1d(g0_row, g1_row, device)\n",
    "\n",
    "    g0_col = g0_col.reshape((1, 1, -1, 1))\n",
    "    g1_col = g1_col.reshape((1, 1, -1, 1))\n",
    "    g0_row = g0_row.reshape((1, 1, 1, -1))\n",
    "    g1_row = g1_row.reshape((1, 1, 1, -1))\n",
    "\n",
    "    return g0_col, g1_col, g0_row, g1_row\n",
    "\n",
    "def sfb2d(ll, lh, hl, hh, filts):\n",
    "    tensorize = [not isinstance(x, torch.Tensor) for x in filts]\n",
    "    if len(filts) == 2:\n",
    "        g0, g1 = filts\n",
    "        if True in tensorize:\n",
    "            g0_col, g1_col, g0_row, g1_row = prep_filt_sfb2d(g0, g1)\n",
    "        else:\n",
    "            g0_col = g0\n",
    "            g0_row = g0.transpose(2,3)\n",
    "            g1_col = g1\n",
    "            g1_row = g1.transpose(2,3)\n",
    "    elif len(filts) == 4:\n",
    "        if True in tensorize:\n",
    "            g0_col, g1_col, g0_row, g1_row = prep_filt_sfb2d(*filts)\n",
    "        else:\n",
    "            g0_col, g1_col, g0_row, g1_row = filts\n",
    "    else:\n",
    "        raise ValueError(\"Unknown form for input filts\")\n",
    "\n",
    "    lo = sfb1d(ll, lh, g0_col, g1_col, dim=2)\n",
    "    hi = sfb1d(hl, hh, g0_col, g1_col, dim=2)\n",
    "    y = sfb1d(lo, hi, g0_row, g1_row, dim=3)\n",
    "\n",
    "    return y\n",
    "        \n",
    "class SFB2D(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, low, highs, g0_row, g1_row, g0_col, g1_col):\n",
    "        ctx.save_for_backward(g0_row, g1_row, g0_col, g1_col)\n",
    "\n",
    "        lh, hl, hh = torch.unbind(highs, dim=2)\n",
    "        lo = sfb1d(low, lh, g0_col, g1_col, dim=2)\n",
    "        hi = sfb1d(hl, hh, g0_col, g1_col, dim=2)\n",
    "        y = sfb1d(lo, hi, g0_row, g1_row, dim=3)\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, dy):\n",
    "        dlow, dhigh = None, None\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            g0_row, g1_row, g0_col, g1_col = ctx.saved_tensors\n",
    "            dx = afb1d(dy, g0_row, g1_row, dim=3)\n",
    "            dx = afb1d(dx, g0_col, g1_col, dim=2)\n",
    "            s = dx.shape\n",
    "            dx = dx.reshape(s[0], -1, 4, s[-2], s[-1])\n",
    "            dlow = dx[:,:,0].contiguous()\n",
    "            dhigh = dx[:,:,1:].contiguous()\n",
    "        return dlow, dhigh, None, None, None, None, None\n",
    "\n",
    "class DWT2DForward(nn.Module):\n",
    "    def __init__(self, J=1, wave='db1'):\n",
    "        super().__init__()\n",
    "        if isinstance(wave, str):\n",
    "            wave = pywt.Wavelet(wave)\n",
    "        if isinstance(wave, pywt.Wavelet):\n",
    "            h0_col, h1_col = wave.dec_lo, wave.dec_hi\n",
    "            h0_row, h1_row = h0_col, h1_col\n",
    "        else:\n",
    "            if len(wave) == 2:\n",
    "                h0_col, h1_col = wave[0], wave[1]\n",
    "                h0_row, h1_row = h0_col, h1_col\n",
    "            elif len(wave) == 4:\n",
    "                h0_col, h1_col = wave[0], wave[1]\n",
    "                h0_row, h1_row = wave[2], wave[3]\n",
    "        filts = prep_filt_afb2d(h0_col, h1_col, h0_row, h1_row)\n",
    "        self.register_buffer('h0_col', filts[0])\n",
    "        self.register_buffer('h1_col', filts[1])\n",
    "        self.register_buffer('h0_row', filts[2])\n",
    "        self.register_buffer('h1_row', filts[3])\n",
    "        self.J = J\n",
    "\n",
    "    def forward(self, x):\n",
    "        yh = []\n",
    "        ll = x\n",
    "        for j in range(self.J):\n",
    "            ll, high = AFB2D.apply(\n",
    "                ll, self.h0_col, self.h1_col, self.h0_row, self.h1_row)\n",
    "            yh.append(high)\n",
    "        return ll, yh\n",
    "\n",
    "class WPT2D(torch.nn.Module):\n",
    "    def __init__(self, wt=DWT2DForward(wave='bior4.4'), J=4):\n",
    "        super().__init__()\n",
    "        self.wt  = wt\n",
    "        self.J = J\n",
    "    def analysis_one_level(self,x):\n",
    "        L, H = self.wt(x)\n",
    "        X = torch.cat([L.unsqueeze(2),H[0]],dim=2)\n",
    "        X = einops.rearrange(X, 'b c f h w -> b (c f) h w')\n",
    "        return X\n",
    "    def wavelet_analysis(self,x,J):\n",
    "        for _ in range(J):\n",
    "            x = self.analysis_one_level(x)\n",
    "        return x\n",
    "    def forward(self, x):\n",
    "        return self.wavelet_analysis(x,J=self.J)\n",
    "\n",
    "class DWT2DInverse(nn.Module):\n",
    "    def __init__(self, wave='db1'):\n",
    "        super().__init__()\n",
    "        if isinstance(wave, str):\n",
    "            wave = pywt.Wavelet(wave)\n",
    "        if isinstance(wave, pywt.Wavelet):\n",
    "            g0_col, g1_col = wave.rec_lo, wave.rec_hi\n",
    "            g0_row, g1_row = g0_col, g1_col\n",
    "        else:\n",
    "            if len(wave) == 2:\n",
    "                g0_col, g1_col = wave[0], wave[1]\n",
    "                g0_row, g1_row = g0_col, g1_col\n",
    "            elif len(wave) == 4:\n",
    "                g0_col, g1_col = wave[0], wave[1]\n",
    "                g0_row, g1_row = wave[2], wave[3]\n",
    "        filts = prep_filt_sfb2d(g0_col, g1_col, g0_row, g1_row)\n",
    "        self.register_buffer('g0_col', filts[0])\n",
    "        self.register_buffer('g1_col', filts[1])\n",
    "        self.register_buffer('g0_row', filts[2])\n",
    "        self.register_buffer('g1_row', filts[3])\n",
    "\n",
    "    def forward(self, coeffs):\n",
    "        yl, yh = coeffs\n",
    "        ll = yl\n",
    "        for h in yh[::-1]:\n",
    "            if h is None:\n",
    "                h = torch.zeros(ll.shape[0], ll.shape[1], 3, ll.shape[-2], ll.shape[-1], device=ll.device)\n",
    "            if ll.shape[-2] > h.shape[-2]:\n",
    "                ll = ll[...,:-1,:]\n",
    "            if ll.shape[-1] > h.shape[-1]:\n",
    "                ll = ll[...,:-1]\n",
    "            ll = SFB2D.apply(ll, h, self.g0_col, self.g1_col, self.g0_row, self.g1_row)\n",
    "        return ll\n",
    "\n",
    "class IWPT2D(torch.nn.Module):\n",
    "    def __init__(self, iwt=DWT2DInverse(wave='bior4.4'), J=4):\n",
    "        super().__init__()\n",
    "        self.iwt  = iwt\n",
    "        self.J = J\n",
    "    def synthesis_one_level(self,X):\n",
    "        X = einops.rearrange(X, 'b (c f) h w -> b c f h w', f=4)\n",
    "        L, H = torch.split(X, [1, 3], dim=2)\n",
    "        L = L.squeeze(2)\n",
    "        H = [H]\n",
    "        y = self.iwt((L, H))\n",
    "        return y\n",
    "    def wavelet_synthesis(self,x,J):\n",
    "        for _ in range(J):\n",
    "            x = self.synthesis_one_level(x)\n",
    "        return x\n",
    "    def forward(self, x):\n",
    "        return self.wavelet_synthesis(x,J=self.J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de33e550-8c4e-439c-b8e8-a78c12a097a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2d = torch.randn(2, 3, 64, 64)\n",
    "wt2d = DWT2DForward(wave='bior4.4')\n",
    "wpt2d = WPT2D(wt=wt2d, J=3)\n",
    "iwt2d = DWT2DInverse(wave='bior4.4')\n",
    "iwpt2d = IWPT2D(iwt=iwt2d, J=3)\n",
    "with torch.no_grad():\n",
    "    X2d = wpt2d(x2d)\n",
    "    xhat2d = iwpt2d(X2d)\n",
    "assert (xhat2d - x2d).abs().max() < 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2446bac8-ddfc-46bc-9f95-bc75df30779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_filt_afb3d(h0_x, h1_x,\n",
    "                    h0_y=None, h1_y=None,\n",
    "                    h0_z=None, h1_z=None,\n",
    "                    device=None):\n",
    "    # If not provided, default Y/Z filters to the X filters\n",
    "    if h0_y is None or h1_y is None:\n",
    "        h0_y, h1_y = h0_x, h1_x\n",
    "    if h0_z is None or h1_z is None:\n",
    "        h0_z, h1_z = h0_x, h1_x\n",
    "    # Prepare 1D filters for each dimension\n",
    "    h0_x, h1_x = prep_filt_afb1d(h0_x, h1_x, device=device)\n",
    "    h0_y, h1_y = prep_filt_afb1d(h0_y, h1_y, device=device)\n",
    "    h0_z, h1_z = prep_filt_afb1d(h0_z, h1_z, device=device)\n",
    "    h0_x = h0_x.reshape(1, 1, -1, 1, 1)\n",
    "    h1_x = h1_x.reshape(1, 1, -1, 1, 1)\n",
    "    h0_y = h0_y.reshape(1, 1, 1, -1, 1)\n",
    "    h1_y = h1_y.reshape(1, 1, 1, -1, 1)\n",
    "    h0_z = h0_z.reshape(1, 1, 1, 1, -1)\n",
    "    h1_z = h1_z.reshape(1, 1, 1, 1, -1)\n",
    "    return h0_x, h1_x, h0_y, h1_y, h0_z, h1_z\n",
    "\n",
    "def afb3d(x, filts):\n",
    "    # Unpack filters\n",
    "    if len(filts) == 2:\n",
    "        h0 = filts[0]\n",
    "        h1 = filts[1]\n",
    "        h0_x, h1_x = h0, h1\n",
    "        h0_y, h1_y = h0, h1\n",
    "        h0_z, h1_z = h0, h1\n",
    "    elif len(filts) == 6:\n",
    "        h0_x, h1_x, h0_y, h1_y, h0_z, h1_z = filts\n",
    "    else:\n",
    "        raise ValueError(\"Unknown form for input filts; expected length 2 or 6.\")\n",
    "\n",
    "    # Helper: apply the 1D analysis filter bank (afb1d) along one axis of a 5D tensor.\n",
    "    # It reshapes the input into 4D, calls afb1d (which uses conv2d), then restores the shape.\n",
    "    def _afb1d_along_axis(x, h0, h1, axis):\n",
    "        # x: (B, C, D, H, W)\n",
    "        B, C, D, H, W = x.shape\n",
    "        if axis == 4:  # along z-axis (width)\n",
    "            # Merge D and H into the batch dimension.\n",
    "            x_reshaped = x.reshape(B * D * H, C, W)            # (B*D*H, C, W)\n",
    "            x_reshaped = x_reshaped.unsqueeze(2)                # (B*D*H, C, 1, W)\n",
    "            # Apply 1D filter along last dimension (dim=3) using afb1d.\n",
    "            out = afb1d(x_reshaped, h0, h1, dim=3)              # (B*D*H, 2*C, 1, new_W)\n",
    "            new_W = out.shape[-1]\n",
    "            out = out.squeeze(2)                                # (B*D*H, 2*C, new_W)\n",
    "            # Reshape back to (B, 2*C, D, H, new_W)\n",
    "            out = out.reshape(B, D, H, 2 * C, new_W).permute(0, 3, 1, 2, 4)\n",
    "            return out\n",
    "        elif axis == 3:  # along y-axis (height)\n",
    "            # Merge D and W into the batch dimension.\n",
    "            x_reshaped = x.reshape(B * D * W, C, H)            # (B*D*W, C, H)\n",
    "            x_reshaped = x_reshaped.unsqueeze(2)               # (B*D*W, C, 1, H)\n",
    "            out = afb1d(x_reshaped, h0, h1, dim=3)             # (B*D*W, 2*C, 1, new_H)\n",
    "            new_H = out.shape[-1]\n",
    "            out = out.squeeze(2)                               # (B*D*W, 2*C, new_H)\n",
    "            # Reshape back to (B, 2*C, D, new_H, W)\n",
    "            out = out.reshape(B, D, W, 2 * C, new_H).permute(0, 3, 1, 4, 2)\n",
    "            return out\n",
    "        elif axis == 2:  # along x-axis (depth)\n",
    "            # Merge H and W into the batch dimension.\n",
    "            x_reshaped = x.reshape(B * H * W, C, D)            # (B*H*W, C, D)\n",
    "            x_reshaped = x_reshaped.unsqueeze(2)               # (B*H*W, C, 1, D)\n",
    "            out = afb1d(x_reshaped, h0, h1, dim=3)             # (B*H*W, 2*C, 1, new_D)\n",
    "            new_D = out.shape[-1]\n",
    "            out = out.squeeze(2)                               # (B*H*W, 2*C, new_D)\n",
    "            # Reshape back to (B, 2*C, new_D, H, W)\n",
    "            out = out.reshape(B, H, W, 2 * C, new_D).permute(0, 3, 4, 1, 2)\n",
    "            return out\n",
    "        else:\n",
    "            raise ValueError(\"Axis must be 2, 3, or 4 for 3D input.\")\n",
    "\n",
    "    # Sequentially apply the 1D filter banks along z, then y, then x.\n",
    "    out_z = _afb1d_along_axis(x, h0_z, h1_z, axis=4)  # -> shape: (B, 2*C, D, H, W_z)\n",
    "    out_y = _afb1d_along_axis(out_z, h0_y, h1_y, axis=3)  # -> shape: (B, 4*C, D, H_y, W_z)\n",
    "    out_x = _afb1d_along_axis(out_y, h0_x, h1_x, axis=2)  # -> shape: (B, 8*C, D_x, H_y, W_z)\n",
    "\n",
    "    # Group the channel dimension to separate the eight subbands.\n",
    "    B, ch8, new_D, new_H, new_W = out_x.shape\n",
    "    C_orig = ch8 // 8\n",
    "    out_x = out_x.reshape(B, C_orig, 8, new_D, new_H, new_W)\n",
    "    # The 0th index is the lowpass (approximation) subband; the remaining 7 are details.\n",
    "    low = out_x[:, :, 0, :, :, :]\n",
    "    highs = out_x[:, :, 1:, :, :, :]\n",
    "    return low, highs\n",
    "\n",
    "def prep_filt_afb3d(h0_x, h1_x,\n",
    "                    h0_y=None, h1_y=None,\n",
    "                    h0_z=None, h1_z=None,\n",
    "                    device=None):\n",
    "    # If not provided, default Y/Z filters to X filters\n",
    "    if h0_y is None or h1_y is None:\n",
    "        h0_y, h1_y = h0_x, h1_x\n",
    "    if h0_z is None or h1_z is None:\n",
    "        h0_z, h1_z = h0_x, h1_x\n",
    "\n",
    "    # Prepare them as 1D filters\n",
    "    h0_x, h1_x = prep_filt_afb1d(h0_x, h1_x, device=device)\n",
    "    h0_y, h1_y = prep_filt_afb1d(h0_y, h1_y, device=device)\n",
    "    h0_z, h1_z = prep_filt_afb1d(h0_z, h1_z, device=device)\n",
    "\n",
    "    # Reshape into (1,1,...) for conv usage\n",
    "    # X-filters will be convolved along the depth (dim=2),\n",
    "    # Y-filters along height (dim=3), Z-filters along width (dim=4).\n",
    "    h0_x = h0_x.reshape(1, 1, -1, 1, 1)\n",
    "    h1_x = h1_x.reshape(1, 1, -1, 1, 1)\n",
    "\n",
    "    h0_y = h0_y.reshape(1, 1, 1, -1, 1)\n",
    "    h1_y = h1_y.reshape(1, 1, 1, -1, 1)\n",
    "\n",
    "    h0_z = h0_z.reshape(1, 1, 1, 1, -1)\n",
    "    h1_z = h1_z.reshape(1, 1, 1, 1, -1)\n",
    "\n",
    "    return h0_x, h1_x, h0_y, h1_y, h0_z, h1_z\n",
    "\n",
    "\n",
    "def afb3d(x, filts):\n",
    "\n",
    "    # Unpack filters\n",
    "    if len(filts) == 2:\n",
    "        # same filters for all dimensions\n",
    "        h0 = filts[0]\n",
    "        h1 = filts[1]\n",
    "        h0_x, h1_x = h0, h1\n",
    "        h0_y, h1_y = h0, h1\n",
    "        h0_z, h1_z = h0, h1\n",
    "    elif len(filts) == 6:\n",
    "        h0_x, h1_x, h0_y, h1_y, h0_z, h1_z = filts\n",
    "    else:\n",
    "        raise ValueError(\"filts must be either length 2 or 6 for AFB3D.\")\n",
    "\n",
    "    B, C, D, H, W = x.shape\n",
    "\n",
    "    # -- Helper: apply AFB1D along a particular axis of a 5D tensor --\n",
    "    def _afb1d_along_axis(x_5d, h0, h1, axis):\n",
    "        Bx, Cx, Dx, Hx, Wx = x_5d.shape\n",
    "        if axis == 4:\n",
    "            # axis = width\n",
    "            # merge (B, D, H) into the batch for the 1D call\n",
    "            x_reshaped = x_5d.permute(0, 2, 3, 1, 4)  # (B, D, H, C, W)\n",
    "            x_reshaped = x_reshaped.reshape(Bx * Dx * Hx, Cx, Wx)  # (batch, C, L)\n",
    "            x_reshaped = x_reshaped[:, :, None, :]                 # (batch, C, 1, W)\n",
    "\n",
    "            lohi = afb1d(x_reshaped, h0, h1, dim=3)  # returns (batch, 2*C, 1, newW)\n",
    "            # shape out: (batch, 2*C, 1, newW)\n",
    "            outC = lohi.shape[1]\n",
    "            outW = lohi.shape[-1]\n",
    "            lohi = lohi.squeeze(2)  # (batch, 2*C, newW)\n",
    "\n",
    "            # reshape back to (B, 2*C, D, H, W')\n",
    "            lohi = lohi.reshape(Bx, Dx, Hx, outC, outW)\n",
    "            lohi = lohi.permute(0, 3, 1, 2, 4)  # (B, outC, D, H, W')\n",
    "            return lohi\n",
    "\n",
    "        elif axis == 3:\n",
    "            # axis = height\n",
    "            x_reshaped = x_5d.permute(0, 2, 4, 1, 3)  # (B, D, W, C, H)\n",
    "            x_reshaped = x_reshaped.reshape(Bx * Dx * Wx, Cx, Hx)\n",
    "            x_reshaped = x_reshaped[:, :, None, :]  # (batch, C, 1, H)\n",
    "\n",
    "            lohi = afb1d(x_reshaped, h0, h1, dim=3)  # (batch, 2*C, 1, newH)\n",
    "            outC = lohi.shape[1]\n",
    "            outH = lohi.shape[-1]\n",
    "            lohi = lohi.squeeze(2)  # (batch, 2*C, newH)\n",
    "\n",
    "            # reshape back\n",
    "            lohi = lohi.reshape(Bx, Dx, Wx, outC, outH)\n",
    "            lohi = lohi.permute(0, 3, 1, 4, 2)  # (B, outC, D, newH, W)\n",
    "            return lohi\n",
    "\n",
    "        elif axis == 2:\n",
    "            # axis = depth\n",
    "            x_reshaped = x_5d.permute(0, 3, 4, 1, 2)  # (B, H, W, C, D)\n",
    "            x_reshaped = x_reshaped.reshape(Bx * Hx * Wx, Cx, Dx)\n",
    "            x_reshaped = x_reshaped[:, :, None, :]  # (batch, C, 1, D)\n",
    "\n",
    "            lohi = afb1d(x_reshaped, h0, h1, dim=3)  # (batch, 2*C, 1, newD)\n",
    "            outC = lohi.shape[1]\n",
    "            outD = lohi.shape[-1]\n",
    "            lohi = lohi.squeeze(2)  # (batch, 2*C, newD)\n",
    "\n",
    "            # reshape back\n",
    "            lohi = lohi.reshape(Bx, Hx, Wx, outC, outD)\n",
    "            lohi = lohi.permute(0, 3, 4, 1, 2)  # (B, outC, newD, H, W)\n",
    "            return lohi\n",
    "        else:\n",
    "            raise ValueError(\"Axis must be one of (2,3,4) for a (B,C,D,H,W) tensor.\")\n",
    "\n",
    "    # 1) Filter along Z (width=dim=4)\n",
    "    out_z = _afb1d_along_axis(x, h0_z, h1_z, axis=4)  # shape: (B, 2C, D, H, Wz)\n",
    "    # 2) Filter along Y (height=dim=3)\n",
    "    out_y = _afb1d_along_axis(out_z, h0_y, h1_y, axis=3)  # shape: (B, 4C, D, Hy, Wz)\n",
    "    # 3) Filter along X (depth=dim=2)\n",
    "    out_x = _afb1d_along_axis(out_y, h0_x, h1_x, axis=2)  # shape: (B, 8C, Dx, Hy, Wz)\n",
    "\n",
    "    # Now separate the 8 subbands in the channel dimension:\n",
    "    B2, ch8, Dx, Hy, Wz = out_x.shape\n",
    "    assert (ch8 % 8) == 0, \"Channel dimension must be multiple of 8.\"\n",
    "    C2 = ch8 // 8\n",
    "\n",
    "    # Reshape to (B, C2, 8, D', H', W')\n",
    "    out_x = out_x.view(B2, C2, 8, Dx, Hy, Wz)\n",
    "\n",
    "    # The [0]-th subband is the lowpass\n",
    "    low = out_x[:, :, 0, :, :, :]    # (B, C2, Dx, Hy, Wz)\n",
    "    # The other [1..7] are the highpass\n",
    "    highs = out_x[:, :, 1:, :, :, :] # (B, C2, 7, Dx, Hy, Wz)\n",
    "\n",
    "    return low, highs\n",
    "\n",
    "\n",
    "class AFB3D(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, h0_x, h1_x, h0_y, h1_y, h0_z, h1_z):\n",
    "        ctx.save_for_backward(h0_x, h1_x, h0_y, h1_y, h0_z, h1_z)\n",
    "        # Save original D,H,W for potential odd-size correction in backward\n",
    "        ctx.original_shape = x.shape[-3:]\n",
    "\n",
    "        # Perform forward 3D decomposition\n",
    "        low, highs = afb3d(x, (h0_x, h1_x, h0_y, h1_y, h0_z, h1_z))\n",
    "        return low, highs\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, dlow, dhigh):\n",
    "        dx = None\n",
    "        if ctx.needs_input_grad[0]:\n",
    "            # Retrieve saved filters\n",
    "            h0_x, h1_x, h0_y, h1_y, h0_z, h1_z = ctx.saved_tensors\n",
    "            # Call your 3D synthesis filter bank (you must implement sfb3d(...) similarly!)\n",
    "            dx = sfb3d(dlow, dhigh, (h0_x, h1_x, h0_y, h1_y, h0_z, h1_z))\n",
    "            \n",
    "            # If the original D,H,W were odd, dx might be one sample longer\n",
    "            D, H, W = ctx.original_shape\n",
    "            if dx.shape[-3] > D:\n",
    "                dx = dx[..., :D, :, :]\n",
    "            if dx.shape[-2] > H:\n",
    "                dx = dx[..., :H, :]\n",
    "            if dx.shape[-1] > W:\n",
    "                dx = dx[..., :W]\n",
    "\n",
    "        # The rest of the returned gradients (for the filters) are None\n",
    "        return dx, None, None, None, None, None, None\n",
    "\n",
    "def prep_filt_sfb3d(g0_x, g1_x,\n",
    "                    g0_y=None, g1_y=None,\n",
    "                    g0_z=None, g1_z=None,\n",
    "                    device=None):\n",
    "    # If Y or Z filters not provided, default to the X filters\n",
    "    if g0_y is None or g1_y is None:\n",
    "        g0_y, g1_y = g0_x, g1_x\n",
    "    if g0_z is None or g1_z is None:\n",
    "        g0_z, g1_z = g0_x, g1_x\n",
    "\n",
    "    # Prep them as standard 1D synthesis filters\n",
    "    g0_x, g1_x = prep_filt_sfb1d(g0_x, g1_x, device=device)\n",
    "    g0_y, g1_y = prep_filt_sfb1d(g0_y, g1_y, device=device)\n",
    "    g0_z, g1_z = prep_filt_sfb1d(g0_z, g1_z, device=device)\n",
    "\n",
    "    # Reshape for use with 3D transposed convolutions:\n",
    "    #  - X filters: (1,1,L,1,1)\n",
    "    #  - Y filters: (1,1,1,L,1)\n",
    "    #  - Z filters: (1,1,1,1,L)\n",
    "    g0_x = g0_x.reshape(1, 1, -1, 1, 1)\n",
    "    g1_x = g1_x.reshape(1, 1, -1, 1, 1)\n",
    "\n",
    "    g0_y = g0_y.reshape(1, 1, 1, -1, 1)\n",
    "    g1_y = g1_y.reshape(1, 1, 1, -1, 1)\n",
    "\n",
    "    g0_z = g0_z.reshape(1, 1, 1, 1, -1)\n",
    "    g1_z = g1_z.reshape(1, 1, 1, 1, -1)\n",
    "\n",
    "    return g0_x, g1_x, g0_y, g1_y, g0_z, g1_z\n",
    "\n",
    "def _sfb1d_along_axis(x_5d, g0, g1, axis):\n",
    "    Bx, Cx, Dx, Hx, Wx = x_5d.shape\n",
    "    # The channel count must be even since it represents concatenated low/high bands.\n",
    "    assert Cx % 2 == 0, \"Channel dimension must be even for synthesis along an axis.\"\n",
    "    \n",
    "    if axis == 4:\n",
    "        # Synthesis along width.\n",
    "        # Permute so that width becomes the last dimension in a (B, D, H, C, W) tensor.\n",
    "        x_perm = x_5d.permute(0, 2, 3, 1, 4).contiguous()  # (B, D, H, C, W)\n",
    "        x_reshaped = x_perm.view(Bx * Dx * Hx, Cx, Wx)       # (B*D*H, C, W)\n",
    "        \n",
    "    elif axis == 3:\n",
    "        # Synthesis along height.\n",
    "        # Permute so that height is last: (B, D, W, C, H)\n",
    "        x_perm = x_5d.permute(0, 2, 4, 1, 3).contiguous()    # (B, D, W, C, H)\n",
    "        x_reshaped = x_perm.view(Bx * Dx * Wx, Cx, Hx)       # (B*D*W, C, H)\n",
    "        \n",
    "    elif axis == 2:\n",
    "        # Synthesis along depth.\n",
    "        # Permute so that depth is last: (B, H, W, C, D)\n",
    "        x_perm = x_5d.permute(0, 3, 4, 1, 2).contiguous()    # (B, H, W, C, D)\n",
    "        x_reshaped = x_perm.view(Bx * Hx * Wx, Cx, Dx)       # (B*H*W, C, D)\n",
    "    else:\n",
    "        raise ValueError(\"Axis must be one of 2 (depth), 3 (height), or 4 (width).\")\n",
    "    \n",
    "    # Split the channel dimension into two halves: low and high parts.\n",
    "    lo = x_reshaped[:, :Cx // 2, :]\n",
    "    hi = x_reshaped[:, Cx // 2:, :]\n",
    "    # sfb1d expects inputs of shape (N, C, 1, L), so add a singleton dimension.\n",
    "    lo = lo.unsqueeze(2)  # shape: (N, C//2, 1, L)\n",
    "    hi = hi.unsqueeze(2)\n",
    "    # Apply 1D synthesis along the last dimension.\n",
    "    y = sfb1d(lo, hi, g0, g1, dim=3)  # (N, C//2, 1, new_L)\n",
    "    y = y.squeeze(2)  # now shape: (N, C//2, new_L)\n",
    "    \n",
    "    new_L = y.shape[-1]\n",
    "    # Reshape and invert the permutation to return to 5D.\n",
    "    if axis == 4:\n",
    "        y = y.view(Bx, Dx, Hx, Cx // 2, new_L)   # (B, D, H, C//2, new_W)\n",
    "        y = y.permute(0, 3, 1, 2, 4).contiguous()   # (B, C//2, D, H, new_W)\n",
    "    elif axis == 3:\n",
    "        y = y.view(Bx, Dx, Wx, Cx // 2, new_L)       # (B, D, W, C//2, new_H)\n",
    "        y = y.permute(0, 3, 1, 4, 2).contiguous()      # (B, C//2, D, new_H, W)\n",
    "    elif axis == 2:\n",
    "        y = y.view(Bx, Hx, Wx, Cx // 2, new_L)       # (B, H, W, C//2, new_D)\n",
    "        y = y.permute(0, 3, 4, 1, 2).contiguous()      # (B, C//2, new_D, H, W)\n",
    "    return y\n",
    "\n",
    "def sfb3d(low, highs, filts):\n",
    "    # Combine the subbands along a new subband axis.\n",
    "    # low is the 0th subband; highs are the remaining 7.\n",
    "    Y = torch.cat([low.unsqueeze(2), highs], dim=2)  # shape: (B, C, 8, D, H, W)\n",
    "    B, C, eight, D, H, W = Y.shape\n",
    "    # Collapse the subband axis into the channel dimension.\n",
    "    Y = Y.view(B, C * eight, D, H, W)  # shape: (B, 8C, D, H, W)\n",
    "    \n",
    "    # Unpack synthesis filters.\n",
    "    g0_x, g1_x, g0_y, g1_y, g0_z, g1_z = filts\n",
    "    \n",
    "    # Reverse the analysis steps in the opposite order.\n",
    "    # Analysis was: first along width (axis 4), then height (axis 3), then depth (axis 2).\n",
    "    # Therefore, synthesis is performed in the order: along depth, then height, then width.\n",
    "    Y = _sfb1d_along_axis(Y, g0_x, g1_x, axis=2)  # Combine subbands along depth.\n",
    "    Y = _sfb1d_along_axis(Y, g0_y, g1_y, axis=3)  # Then along height.\n",
    "    Y = _sfb1d_along_axis(Y, g0_z, g1_z, axis=4)  # Finally along width.\n",
    "    \n",
    "    return Y\n",
    "\n",
    "class SFB3D(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, low, highs, g0_x, g1_x, g0_y, g1_y, g0_z, g1_z):\n",
    "        ctx.save_for_backward(g0_x, g1_x, g0_y, g1_y, g0_z, g1_z)\n",
    "        y = sfb3d(low, highs, (g0_x, g1_x, g0_y, g1_y, g0_z, g1_z))\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, dy):\n",
    "        g0_x, g1_x, g0_y, g1_y, g0_z, g1_z = ctx.saved_tensors\n",
    "        dlow, dhigh = afb3d(dy, (g0_x, g1_x, g0_y, g1_y, g0_z, g1_z))\n",
    "        return dlow, dhigh, None, None, None, None, None, None\n",
    "\n",
    "class DWT3DForward(nn.Module):\n",
    "    def __init__(self, J=1, wave='db1'):\n",
    "        super().__init__()\n",
    "        # Process the wave parameter\n",
    "        if isinstance(wave, str):\n",
    "            wave = pywt.Wavelet(wave)\n",
    "        if isinstance(wave, pywt.Wavelet):\n",
    "            # Use the same decomposition filters for all dimensions.\n",
    "            h0_x, h1_x = wave.dec_lo, wave.dec_hi\n",
    "            h0_y, h1_y = h0_x, h1_x\n",
    "            h0_z, h1_z = h0_x, h1_x\n",
    "        else:\n",
    "            # Allow either a 2-tuple or a 6-tuple.\n",
    "            if len(wave) == 2:\n",
    "                h0_x, h1_x = wave[0], wave[1]\n",
    "                h0_y, h1_y = h0_x, h1_x\n",
    "                h0_z, h1_z = h0_x, h1_x\n",
    "            elif len(wave) == 6:\n",
    "                h0_x, h1_x = wave[0], wave[1]\n",
    "                h0_y, h1_y = wave[2], wave[3]\n",
    "                h0_z, h1_z = wave[4], wave[5]\n",
    "            else:\n",
    "                raise ValueError(\"wave must be either a 2-tuple or a 6-tuple of filters.\")\n",
    "        \n",
    "        # Preprocess filters for the 3D analysis bank.\n",
    "        filts = prep_filt_afb3d(h0_x, h1_x, h0_y, h1_y, h0_z, h1_z)\n",
    "        self.register_buffer('h0_x', filts[0])\n",
    "        self.register_buffer('h1_x', filts[1])\n",
    "        self.register_buffer('h0_y', filts[2])\n",
    "        self.register_buffer('h1_y', filts[3])\n",
    "        self.register_buffer('h0_z', filts[4])\n",
    "        self.register_buffer('h1_z', filts[5])\n",
    "        self.J = J\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert x.ndim == 5, \"DWT3DForward expects a 5D input (B, C, D, H, W)\"\n",
    "        highs = []\n",
    "        ll = x\n",
    "        for j in range(self.J):\n",
    "            # AFB3D.apply returns (low, highs) where highs is a tensor containing the 7 detail subbands.\n",
    "            ll, high = AFB3D.apply(ll, self.h0_x, self.h1_x,\n",
    "                                        self.h0_y, self.h1_y,\n",
    "                                        self.h0_z, self.h1_z)\n",
    "            highs.append(high)\n",
    "        return ll, highs\n",
    "\n",
    "class WPT3D(torch.nn.Module):\n",
    "    def __init__(self, wt=DWT3DForward(wave='bior4.4'), J=4):\n",
    "        super().__init__()\n",
    "        self.wt = wt\n",
    "        self.J = J\n",
    "\n",
    "    def analysis_one_level(self, x):\n",
    "        # Perform one level of 3D DWT.\n",
    "        # L has shape (B, C, D, H, W)\n",
    "        # H is a list where H[0] has shape (B, C, 7, D, H, W)\n",
    "        L, H = self.wt(x)\n",
    "        # Create a new subband axis:\n",
    "        # Unsqueeze L to shape (B, C, 1, D, H, W) and then concatenate with the detail subbands.\n",
    "        X = torch.cat([L.unsqueeze(2), H[0]], dim=2)  # now X has shape (B, C, 8, D, H, W)\n",
    "        # Merge the channel and subband dimensions for a complete wavelet packet representation.\n",
    "        X = einops.rearrange(X, 'b c f d h w -> b (c f) d h w')\n",
    "        return X\n",
    "\n",
    "    def wavelet_analysis(self, x, J):\n",
    "        # Recursively apply one-level analysis J times.\n",
    "        for _ in range(J):\n",
    "            x = self.analysis_one_level(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Expect x to be a 5D tensor: (B, C, D, H, W)\n",
    "        return self.wavelet_analysis(x, J=self.J)\n",
    "\n",
    "class DWT3DInverse(nn.Module):\n",
    "    def __init__(self, wave='db1'):\n",
    "        super().__init__()\n",
    "        # If wave is given as a string, convert to a pywt.Wavelet.\n",
    "        if isinstance(wave, str):\n",
    "            wave = pywt.Wavelet(wave)\n",
    "        # Determine synthesis filters.\n",
    "        if isinstance(wave, pywt.Wavelet):\n",
    "            # Use the same reconstruction filters for all dimensions.\n",
    "            g0_x, g1_x = wave.rec_lo, wave.rec_hi\n",
    "            g0_y, g1_y = g0_x, g1_x\n",
    "            g0_z, g1_z = g0_x, g1_x\n",
    "        else:\n",
    "            # Otherwise, expect either a 2-tuple or a 6-tuple.\n",
    "            if len(wave) == 2:\n",
    "                g0_x, g1_x = wave[0], wave[1]\n",
    "                g0_y, g1_y = g0_x, g1_x\n",
    "                g0_z, g1_z = g0_x, g1_x\n",
    "            elif len(wave) == 6:\n",
    "                g0_x, g1_x = wave[0], wave[1]\n",
    "                g0_y, g1_y = wave[2], wave[3]\n",
    "                g0_z, g1_z = wave[4], wave[5]\n",
    "            else:\n",
    "                raise ValueError(\"wave must be either a 2-tuple or a 6-tuple of filters.\")\n",
    "        # Preprocess the synthesis filters.\n",
    "        filts = prep_filt_sfb3d(g0_x, g1_x, g0_y, g1_y, g0_z, g1_z)\n",
    "        self.register_buffer('g0_x', filts[0])\n",
    "        self.register_buffer('g1_x', filts[1])\n",
    "        self.register_buffer('g0_y', filts[2])\n",
    "        self.register_buffer('g1_y', filts[3])\n",
    "        self.register_buffer('g0_z', filts[4])\n",
    "        self.register_buffer('g1_z', filts[5])\n",
    "\n",
    "    def forward(self, coeffs):\n",
    "        ll, highs = coeffs\n",
    "        # Iterate in reverse order over the detail coefficients.\n",
    "        for h in highs[::-1]:\n",
    "            # If a detail subband is missing, replace with zeros.\n",
    "            if h is None:\n",
    "                h = torch.zeros(ll.shape[0], ll.shape[1], 7,\n",
    "                                ll.shape[-3], ll.shape[-2], ll.shape[-1],\n",
    "                                device=ll.device, dtype=ll.dtype)\n",
    "            # If the lowpass tensor has an extra sample (due to odd sizes), crop it.\n",
    "            if ll.shape[-3] > h.shape[-3]:\n",
    "                ll = ll[..., :-1, :, :]\n",
    "            if ll.shape[-2] > h.shape[-2]:\n",
    "                ll = ll[..., :, :-1, :]\n",
    "            if ll.shape[-1] > h.shape[-1]:\n",
    "                ll = ll[..., :, :, :-1]\n",
    "            # Synthesize the current level using the 3D synthesis filter bank.\n",
    "            ll = SFB3D.apply(ll, h,\n",
    "                             self.g0_x, self.g1_x,\n",
    "                             self.g0_y, self.g1_y,\n",
    "                             self.g0_z, self.g1_z)\n",
    "        return ll\n",
    "\n",
    "class IWPT3D(torch.nn.Module):\n",
    "    def __init__(self, iwt=DWT3DInverse(wave='bior4.4'), J=4):\n",
    "        super().__init__()\n",
    "        self.iwt = iwt\n",
    "        self.J = J\n",
    "\n",
    "    def synthesis_one_level(self, X):\n",
    "        # Rearrange to separate the subband dimension: (B, C, 8, D, H, W)\n",
    "        X = einops.rearrange(X, 'b (c f) d h w -> b c f d h w', f=8)\n",
    "        # Split into lowpass (first subband) and highpass (remaining 7 subbands)\n",
    "        L, H = torch.split(X, [1, 7], dim=2)\n",
    "        # Remove the subband dimension from the lowpass\n",
    "        L = L.squeeze(2)  # now (B, C, D, H, W)\n",
    "        H = H.squeeze(2)  # now (B, C, 7, D, H, W)\n",
    "        # Wrap the detail coefficients in a list (as expected by DWT3DInverse)\n",
    "        y = self.iwt((L, [H]))\n",
    "        return y\n",
    "\n",
    "    def wavelet_synthesis(self, x, J):\n",
    "        for _ in range(J):\n",
    "            x = self.synthesis_one_level(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.wavelet_synthesis(x, J=self.J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38468844-0c26-4e3e-b11f-2269770c0889",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m     X3d \u001b[38;5;241m=\u001b[39m wpt3d(x3d)\n\u001b[1;32m      8\u001b[0m     xhat3d \u001b[38;5;241m=\u001b[39m iwpt3d(X3d)\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (xhat3d \u001b[38;5;241m-\u001b[39m x3d)\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-5\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x3d = torch.randn(2, 3, 16, 16, 16)\n",
    "wt3d = DWT3DForward(wave='bior4.4')\n",
    "wpt3d = WPT3D(wt=wt3d, J=3)\n",
    "iwt3d = DWT3DInverse(wave='bior4.4')\n",
    "iwpt3d = IWPT3D(iwt=iwt3d, J=3)\n",
    "with torch.no_grad():\n",
    "    X3d = wpt3d(x3d)\n",
    "    xhat3d = iwpt3d(X3d)\n",
    "assert (xhat3d - x3d).abs().max() < 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b9f4a67-8c49-4231-8443-25862c82a364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1802)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(xhat3d-x3d).std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
